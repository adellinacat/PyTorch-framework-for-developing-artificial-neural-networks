{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dda8347",
   "metadata": {},
   "source": [
    "### 7. Рекурентные сети для обработки последовательностей\n",
    "Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
    "\n",
    "Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f243b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Инна\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Инна\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Инна\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Инна\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from string import punctuation\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484762f",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5f0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d8bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0bb4e",
   "metadata": {},
   "source": [
    "Зададим ряд гиперпараметров, которые будут использоваться в дальнейшем процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe538ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1500\n",
    "max_len = 15\n",
    "num_classes = 1\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da04a0",
   "metadata": {},
   "source": [
    "Сплитуем данные на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14785e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train['tweet'], \n",
    "                                                  df_train['label'], \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df_train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2ed35",
   "metadata": {},
   "source": [
    "Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e8614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'user',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "# Обработаем сет на наличие стоп-слов\n",
    "# но часто встречается как текстовое представление символа - &amp; \n",
    "sw.add('amp')\n",
    "# Добавим user, так как в данном датасете это является обезличенным \n",
    "# упоминанием пользователя в твите\n",
    "sw.add('user')\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdc2718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Список знаков и спецсимволов\n",
    "puncts = set(punctuation)\n",
    "puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b2f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    # уберем нечитаемые символы типа  ð\\x9f¤\\x97\n",
    "    txt = \"\".join([c for c in txt if ord(c) < 128])\n",
    "    txt = \"\".join(c for c in txt if c not in puncts)\n",
    "    txt = txt.lower()\n",
    "    # преобразуем отрицания\n",
    "    txt = re.sub(\"not\\s\", \"not\", txt)\n",
    "    txt = re.sub(\"no\\s\", \"no\", txt)\n",
    "    # будем приводить формы к глаголам\n",
    "    txt = [Word(word).lemmatize('v') for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf0c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy bihday to my brother man. needed this mixtape like we need boos. have a good one sach   @user ',\n",
       "       '  lang to sta the week right :)  #happiness #smile ',\n",
       "       'note it meditate on it work on it ,but most impoantly trust god for it #icantwaitfohedayhisplansformylifeunfold #grateful  ',\n",
       "       '@user listening to you this wet mon, ahead of #leedsmillenium gig next month   ð\\x9f\\x98\\x86ð\\x9f\\x91\\x8dð\\x9f\\x98\\x8d #music #ace ',\n",
       "       '@user @user agreed.. the same is true for  and .. they are overused terms, and as a result, are fast becominâ\\x80¦',\n",
       "       'very exciting! #dubllife #recycle ',\n",
       "       '#bad times #drink   #nobev ',\n",
       "       '#ootd #converse #denim #tshi  #shopping  #like4like #l4l #f4f #instagood  ',\n",
       "       '  #fathersday to the man of my dreams! you sacrificed bachelorhood for a ready-made familyâ\\x80¦ ',\n",
       "       '  #pougalday #pay #saturday #fresh #new #haircut &amp; new #red #car in #style #chillingâ\\x80¦ '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:10].values #необработанный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa3069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy bihday brother man need mixtape like need boo good one sach',\n",
       "       'lang sta week right happiness smile',\n",
       "       'note meditate work impoantly trust god icantwaitfohedayhisplansformylifeunfold grateful',\n",
       "       'listen wet mon ahead leedsmillenium gig next month music ace',\n",
       "       'agree true overuse term result fast becomin',\n",
       "       'excite dubllife recycle', 'bad time drink nobev',\n",
       "       'ootd converse denim tshi shop like4like l4l f4f instagood',\n",
       "       'fathersday man dream sacrifice bachelorhood readymade family',\n",
       "       'pougalday pay saturday fresh new haircut new red car style chill'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:10].apply(preprocess_text).values #обработанный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a56f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(preprocess_text).values\n",
    "X_val = X_val.apply(preprocess_text).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dae5b8c",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc49c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(X_train)\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a17d364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " 'bihday',\n",
       " 'brother',\n",
       " 'man',\n",
       " 'need',\n",
       " 'mixtape',\n",
       " 'like',\n",
       " 'need',\n",
       " 'boo',\n",
       " 'good']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(train_corpus)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a341fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'day', 'get', 'happy', 'go', 'time', 'make', 'im', 'u', 'life']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
    "\n",
    "# Посмотрим на топ 10 слов\n",
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a9300",
   "metadata": {},
   "source": [
    "Словарь наиболее частотных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b53b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 1),\n",
       " ('day', 2),\n",
       " ('get', 3),\n",
       " ('happy', 4),\n",
       " ('go', 5),\n",
       " ('time', 6),\n",
       " ('make', 7),\n",
       " ('im', 8),\n",
       " ('u', 9),\n",
       " ('life', 10),\n",
       " ('like', 11),\n",
       " ('today', 12),\n",
       " ('new', 13),\n",
       " ('father', 14),\n",
       " ('see', 15),\n",
       " ('positive', 16),\n",
       " ('smile', 17),\n",
       " ('thankful', 18),\n",
       " ('people', 19),\n",
       " ('bihday', 20)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take(n, iterable):\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "take(20, vocabulary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba6722d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "\n",
    "    padding = [0] * (maxlen-len(result))\n",
    "    return result[-maxlen:] + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc08982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train])\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba43f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  20, 887, 131,  31,  11,  31,  21,  28,   0,   0,   0,   0,\n",
       "         0,   0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e369aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd008da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataWrapper(x_train, y_train.values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DataWrapper(x_val, y_val.values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "185c62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f306daf",
   "metadata": {},
   "source": [
    "Инициализируем устройство, на котором будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "797c6af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a270cf",
   "metadata": {},
   "source": [
    "Инициализируем и обучим сеть GRU на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "767225ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [5, 10]\n",
    "learning_rates = [1e-2, 1e-3]\n",
    "e_dims = [128, 256]\n",
    "h_dims = [64, 96]\n",
    "ths = [0.3, 0.5]\n",
    "dps = [0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e328fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "       # self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        #x = self.dropout(x)\n",
    "        gru_out, ht = self.gru(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = gru_out[:,-1,:]\n",
    "        else:\n",
    "            #use mean\n",
    "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f06c462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.159. Acc: 0.898. Test loss: 0.278.Test acc: 0.938\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.154. Acc: 0.952. Test loss: 0.132.Test acc: 0.944\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.111. Acc: 0.960. Test loss: 0.003.Test acc: 0.935\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.087. Acc: 0.969. Test loss: 0.043.Test acc: 0.938\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.066. Acc: 0.976. Test loss: 0.030.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.176. Acc: 0.899. Test loss: 0.065.Test acc: 0.946\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.111. Acc: 0.952. Test loss: 0.018.Test acc: 0.947\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.140. Acc: 0.961. Test loss: 0.550.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.090. Acc: 0.971. Test loss: 1.110.Test acc: 0.942\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.075. Acc: 0.980. Test loss: 0.008.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.128. Acc: 0.898. Test loss: 0.029.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.137. Acc: 0.951. Test loss: 0.094.Test acc: 0.944\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.122. Acc: 0.962. Test loss: 0.128.Test acc: 0.942\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.068. Acc: 0.971. Test loss: 0.393.Test acc: 0.946\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.037. Acc: 0.979. Test loss: 0.011.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.152. Acc: 0.940. Test loss: 0.016.Test acc: 0.951\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.135. Acc: 0.958. Test loss: 0.015.Test acc: 0.953\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.117. Acc: 0.967. Test loss: 0.115.Test acc: 0.953\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.095. Acc: 0.975. Test loss: 0.002.Test acc: 0.948\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.058. Acc: 0.982. Test loss: 0.377.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.149. Acc: 0.923. Test loss: 0.042.Test acc: 0.944\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.088. Acc: 0.954. Test loss: 0.053.Test acc: 0.951\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.111. Acc: 0.962. Test loss: 0.069.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.056. Acc: 0.969. Test loss: 0.064.Test acc: 0.948\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.075. Acc: 0.976. Test loss: 2.142.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.101. Acc: 0.942. Test loss: 0.254.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.142. Acc: 0.956. Test loss: 0.035.Test acc: 0.951\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.125. Acc: 0.963. Test loss: 0.026.Test acc: 0.950\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.133. Acc: 0.972. Test loss: 0.239.Test acc: 0.947\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.084. Acc: 0.980. Test loss: 0.015.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.131. Acc: 0.898. Test loss: 0.025.Test acc: 0.947\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.198. Acc: 0.950. Test loss: 0.090.Test acc: 0.949\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.081. Acc: 0.960. Test loss: 0.010.Test acc: 0.942\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.073. Acc: 0.971. Test loss: 0.019.Test acc: 0.941\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.054. Acc: 0.979. Test loss: 0.142.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.165. Acc: 0.898. Test loss: 0.022.Test acc: 0.946\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.150. Acc: 0.951. Test loss: 0.248.Test acc: 0.947\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.096. Acc: 0.959. Test loss: 0.054.Test acc: 0.940\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.080. Acc: 0.970. Test loss: 1.630.Test acc: 0.946\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.087. Acc: 0.977. Test loss: 0.000.Test acc: 0.937\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.203. Acc: 0.901. Test loss: 0.270.Test acc: 0.941\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.100. Acc: 0.951. Test loss: 0.019.Test acc: 0.946\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.105. Acc: 0.963. Test loss: 0.132.Test acc: 0.947\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.100. Acc: 0.972. Test loss: 0.002.Test acc: 0.941\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.055. Acc: 0.977. Test loss: 1.256.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.223. Acc: 0.924. Test loss: 0.070.Test acc: 0.947\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.124. Acc: 0.955. Test loss: 0.077.Test acc: 0.953\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.103. Acc: 0.965. Test loss: 0.033.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.084. Acc: 0.973. Test loss: 0.102.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.075. Acc: 0.980. Test loss: 0.545.Test acc: 0.953\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.177. Acc: 0.939. Test loss: 0.031.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.101. Acc: 0.956. Test loss: 0.010.Test acc: 0.950\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.084. Acc: 0.964. Test loss: 0.002.Test acc: 0.950\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.072. Acc: 0.971. Test loss: 0.005.Test acc: 0.952\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.093. Acc: 0.980. Test loss: 0.004.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.168. Acc: 0.929. Test loss: 0.032.Test acc: 0.945\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.082. Acc: 0.956. Test loss: 0.762.Test acc: 0.951\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.094. Acc: 0.966. Test loss: 0.414.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.074. Acc: 0.973. Test loss: 0.067.Test acc: 0.946\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.027. Acc: 0.980. Test loss: 0.522.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.108. Acc: 0.901. Test loss: 0.033.Test acc: 0.948\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.139. Acc: 0.956. Test loss: 0.096.Test acc: 0.950\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.133. Acc: 0.964. Test loss: 0.016.Test acc: 0.950\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.056. Acc: 0.975. Test loss: 0.005.Test acc: 0.948\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.027. Acc: 0.983. Test loss: 0.576.Test acc: 0.939\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.181. Acc: 0.901. Test loss: 0.134.Test acc: 0.946\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.160. Acc: 0.954. Test loss: 0.175.Test acc: 0.948\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.055. Acc: 0.965. Test loss: 0.002.Test acc: 0.946\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.080. Acc: 0.975. Test loss: 0.039.Test acc: 0.945\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.068. Acc: 0.980. Test loss: 0.001.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.151. Acc: 0.897. Test loss: 0.028.Test acc: 0.948\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.132. Acc: 0.952. Test loss: 0.016.Test acc: 0.945\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.073. Acc: 0.963. Test loss: 0.313.Test acc: 0.948\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.107. Acc: 0.972. Test loss: 0.009.Test acc: 0.943\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.055. Acc: 0.977. Test loss: 1.044.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.118. Acc: 0.926. Test loss: 0.020.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.149. Acc: 0.957. Test loss: 0.017.Test acc: 0.952\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.095. Acc: 0.967. Test loss: 0.993.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.080. Acc: 0.977. Test loss: 0.003.Test acc: 0.951\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.035. Acc: 0.982. Test loss: 0.012.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.144. Acc: 0.942. Test loss: 0.275.Test acc: 0.950\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.112. Acc: 0.958. Test loss: 0.010.Test acc: 0.951\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.091. Acc: 0.969. Test loss: 0.027.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.069. Acc: 0.978. Test loss: 0.457.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.079. Acc: 0.982. Test loss: 0.002.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.137. Acc: 0.943. Test loss: 0.020.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.098. Acc: 0.959. Test loss: 0.009.Test acc: 0.952\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.121. Acc: 0.968. Test loss: 0.004.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.084. Acc: 0.976. Test loss: 0.176.Test acc: 0.944\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.056. Acc: 0.981. Test loss: 0.004.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.171. Acc: 0.899. Test loss: 0.036.Test acc: 0.944\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.167. Acc: 0.955. Test loss: 0.077.Test acc: 0.942\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.071. Acc: 0.968. Test loss: 0.030.Test acc: 0.945\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.044. Acc: 0.976. Test loss: 0.002.Test acc: 0.948\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.094. Acc: 0.982. Test loss: 0.008.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.139. Acc: 0.911. Test loss: 0.013.Test acc: 0.950\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.146. Acc: 0.955. Test loss: 0.340.Test acc: 0.946\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.089. Acc: 0.968. Test loss: 0.043.Test acc: 0.942\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.976. Test loss: 0.071.Test acc: 0.939\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.045. Acc: 0.982. Test loss: 0.040.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.129. Acc: 0.900. Test loss: 0.016.Test acc: 0.949\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.137. Acc: 0.952. Test loss: 0.017.Test acc: 0.951\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.094. Acc: 0.963. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.056. Acc: 0.973. Test loss: 0.317.Test acc: 0.942\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.094. Acc: 0.981. Test loss: 0.018.Test acc: 0.938\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.155. Acc: 0.923. Test loss: 0.021.Test acc: 0.947\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.088. Acc: 0.958. Test loss: 0.092.Test acc: 0.953\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.067. Acc: 0.967. Test loss: 0.327.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.065. Acc: 0.976. Test loss: 0.646.Test acc: 0.953\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.053. Acc: 0.983. Test loss: 0.119.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.130. Acc: 0.924. Test loss: 0.109.Test acc: 0.950\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.149. Acc: 0.960. Test loss: 0.015.Test acc: 0.952\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.097. Acc: 0.970. Test loss: 0.016.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.061. Acc: 0.977. Test loss: 0.003.Test acc: 0.949\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.063. Acc: 0.984. Test loss: 0.960.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.160. Acc: 0.925. Test loss: 0.067.Test acc: 0.951\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.120. Acc: 0.958. Test loss: 0.018.Test acc: 0.953\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.095. Acc: 0.969. Test loss: 0.015.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.050. Acc: 0.979. Test loss: 0.002.Test acc: 0.949\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.041. Acc: 0.983. Test loss: 0.025.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.241. Acc: 0.644. Test loss: 0.041.Test acc: 0.933\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.217. Acc: 0.939. Test loss: 0.024.Test acc: 0.939\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.151. Acc: 0.947. Test loss: 0.020.Test acc: 0.945\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.144. Acc: 0.952. Test loss: 0.762.Test acc: 0.942\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.106. Acc: 0.955. Test loss: 0.396.Test acc: 0.938\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.215. Acc: 0.653. Test loss: 0.075.Test acc: 0.935\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.167. Acc: 0.939. Test loss: 0.015.Test acc: 0.938\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.109. Acc: 0.947. Test loss: 0.018.Test acc: 0.942\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.952. Test loss: 0.020.Test acc: 0.941\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.107. Acc: 0.955. Test loss: 0.628.Test acc: 0.940\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.260. Acc: 0.667. Test loss: 0.318.Test acc: 0.936\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.167. Acc: 0.940. Test loss: 0.620.Test acc: 0.936\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.113. Acc: 0.944. Test loss: 0.095.Test acc: 0.941\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.098. Acc: 0.949. Test loss: 0.045.Test acc: 0.947\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.186. Acc: 0.955. Test loss: 0.009.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.217. Acc: 0.928. Test loss: 0.560.Test acc: 0.933\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.119. Acc: 0.941. Test loss: 0.308.Test acc: 0.945\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.166. Acc: 0.952. Test loss: 0.059.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.127. Acc: 0.957. Test loss: 0.042.Test acc: 0.951\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.133. Acc: 0.960. Test loss: 0.010.Test acc: 0.953\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.163. Acc: 0.868. Test loss: 0.560.Test acc: 0.934\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.203. Acc: 0.940. Test loss: 0.029.Test acc: 0.943\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.181. Acc: 0.949. Test loss: 0.028.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.117. Acc: 0.956. Test loss: 0.041.Test acc: 0.948\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.145. Acc: 0.960. Test loss: 0.718.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [44/44]. Loss: 0.254. Acc: 0.924. Test loss: 0.655.Test acc: 0.933\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.157. Acc: 0.940. Test loss: 0.035.Test acc: 0.941\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.166. Acc: 0.949. Test loss: 0.112.Test acc: 0.948\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.117. Acc: 0.956. Test loss: 0.033.Test acc: 0.951\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.143. Acc: 0.960. Test loss: 0.726.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.192. Acc: 0.728. Test loss: 0.354.Test acc: 0.934\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.121. Acc: 0.939. Test loss: 0.024.Test acc: 0.939\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.168. Acc: 0.946. Test loss: 0.048.Test acc: 0.945\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.138. Acc: 0.953. Test loss: 0.087.Test acc: 0.947\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.099. Acc: 0.957. Test loss: 0.033.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.194. Acc: 0.729. Test loss: 0.056.Test acc: 0.934\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.136. Acc: 0.940. Test loss: 0.018.Test acc: 0.940\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.160. Acc: 0.948. Test loss: 0.293.Test acc: 0.941\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.143. Acc: 0.952. Test loss: 0.498.Test acc: 0.945\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.081. Acc: 0.956. Test loss: 0.017.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.205. Acc: 0.756. Test loss: 0.052.Test acc: 0.937\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.167. Acc: 0.938. Test loss: 0.024.Test acc: 0.939\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.142. Acc: 0.945. Test loss: 0.054.Test acc: 0.944\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.106. Acc: 0.951. Test loss: 0.897.Test acc: 0.942\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.097. Acc: 0.954. Test loss: 0.056.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.210. Acc: 0.929. Test loss: 0.072.Test acc: 0.935\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.135. Acc: 0.943. Test loss: 0.425.Test acc: 0.944\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.089. Acc: 0.951. Test loss: 0.013.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.135. Acc: 0.957. Test loss: 0.047.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.127. Acc: 0.960. Test loss: 0.005.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.199. Acc: 0.911. Test loss: 0.581.Test acc: 0.937\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.093. Acc: 0.943. Test loss: 0.028.Test acc: 0.946\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.142. Acc: 0.951. Test loss: 0.029.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.164. Acc: 0.956. Test loss: 0.046.Test acc: 0.949\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.096. Acc: 0.960. Test loss: 0.011.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.210. Acc: 0.928. Test loss: 0.056.Test acc: 0.936\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.182. Acc: 0.942. Test loss: 1.185.Test acc: 0.946\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.151. Acc: 0.949. Test loss: 0.956.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.093. Acc: 0.957. Test loss: 0.008.Test acc: 0.951\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.100. Acc: 0.960. Test loss: 0.137.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.244. Acc: 0.686. Test loss: 0.069.Test acc: 0.941\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.150. Acc: 0.944. Test loss: 0.028.Test acc: 0.944\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.129. Acc: 0.953. Test loss: 0.011.Test acc: 0.945\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.165. Acc: 0.958. Test loss: 0.036.Test acc: 0.947\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.105. Acc: 0.964. Test loss: 0.587.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.230. Acc: 0.705. Test loss: 0.038.Test acc: 0.938\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.188. Acc: 0.944. Test loss: 0.049.Test acc: 0.939\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.158. Acc: 0.951. Test loss: 0.027.Test acc: 0.940\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.135. Acc: 0.958. Test loss: 0.028.Test acc: 0.944\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.089. Acc: 0.964. Test loss: 0.066.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.224. Acc: 0.682. Test loss: 0.041.Test acc: 0.941\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.194. Acc: 0.945. Test loss: 0.087.Test acc: 0.942\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.124. Acc: 0.951. Test loss: 0.033.Test acc: 0.946\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.135. Acc: 0.957. Test loss: 0.019.Test acc: 0.946\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.104. Acc: 0.962. Test loss: 0.474.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.175. Acc: 0.931. Test loss: 0.641.Test acc: 0.937\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.153. Acc: 0.945. Test loss: 0.216.Test acc: 0.947\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.152. Acc: 0.957. Test loss: 0.038.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.115. Acc: 0.962. Test loss: 0.011.Test acc: 0.952\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.107. Acc: 0.968. Test loss: 0.365.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.190. Acc: 0.929. Test loss: 0.042.Test acc: 0.937\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.102. Acc: 0.944. Test loss: 0.051.Test acc: 0.948\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.146. Acc: 0.955. Test loss: 0.081.Test acc: 0.949\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.157. Acc: 0.961. Test loss: 0.262.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.083. Acc: 0.967. Test loss: 0.009.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.269. Acc: 0.931. Test loss: 0.046.Test acc: 0.937\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.181. Acc: 0.944. Test loss: 0.060.Test acc: 0.946\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.163. Acc: 0.953. Test loss: 0.082.Test acc: 0.950\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.177. Acc: 0.961. Test loss: 0.043.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.149. Acc: 0.965. Test loss: 0.032.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.173. Acc: 0.746. Test loss: 0.217.Test acc: 0.942\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.168. Acc: 0.944. Test loss: 0.054.Test acc: 0.947\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.123. Acc: 0.954. Test loss: 0.273.Test acc: 0.947\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.088. Acc: 0.959. Test loss: 0.014.Test acc: 0.941\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.107. Acc: 0.965. Test loss: 0.029.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.162. Acc: 0.752. Test loss: 0.250.Test acc: 0.938\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.150. Acc: 0.945. Test loss: 0.034.Test acc: 0.945\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.120. Acc: 0.953. Test loss: 0.040.Test acc: 0.950\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.086. Acc: 0.958. Test loss: 0.013.Test acc: 0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]. Step [44/44]. Loss: 0.101. Acc: 0.964. Test loss: 0.026.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.209. Acc: 0.739. Test loss: 0.537.Test acc: 0.940\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.131. Acc: 0.943. Test loss: 0.668.Test acc: 0.940\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.131. Acc: 0.952. Test loss: 0.015.Test acc: 0.943\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.126. Acc: 0.956. Test loss: 0.027.Test acc: 0.944\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.084. Acc: 0.964. Test loss: 0.018.Test acc: 0.940\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.181. Acc: 0.896. Test loss: 0.055.Test acc: 0.938\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.167. Acc: 0.948. Test loss: 0.037.Test acc: 0.949\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.135. Acc: 0.956. Test loss: 0.534.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.127. Acc: 0.962. Test loss: 0.435.Test acc: 0.951\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.117. Acc: 0.967. Test loss: 0.099.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.120. Acc: 0.931. Test loss: 0.069.Test acc: 0.943\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.158. Acc: 0.948. Test loss: 0.031.Test acc: 0.949\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.152. Acc: 0.956. Test loss: 0.193.Test acc: 0.952\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.124. Acc: 0.962. Test loss: 0.565.Test acc: 0.950\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.140. Acc: 0.967. Test loss: 0.100.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Step [44/44]. Loss: 0.150. Acc: 0.933. Test loss: 0.051.Test acc: 0.943\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.121. Acc: 0.948. Test loss: 0.018.Test acc: 0.947\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.120. Acc: 0.955. Test loss: 0.010.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.126. Acc: 0.961. Test loss: 0.700.Test acc: 0.952\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.149. Acc: 0.965. Test loss: 0.005.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.203. Acc: 0.896. Test loss: 0.107.Test acc: 0.943\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.118. Acc: 0.952. Test loss: 0.511.Test acc: 0.951\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.149. Acc: 0.961. Test loss: 0.020.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.101. Acc: 0.972. Test loss: 0.785.Test acc: 0.940\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.063. Acc: 0.978. Test loss: 0.001.Test acc: 0.939\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.063. Acc: 0.984. Test loss: 0.027.Test acc: 0.937\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.059. Acc: 0.988. Test loss: 0.006.Test acc: 0.939\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.065. Acc: 0.990. Test loss: 0.000.Test acc: 0.945\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.062. Acc: 0.991. Test loss: 0.810.Test acc: 0.945\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.037. Acc: 0.993. Test loss: 0.000.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.126. Acc: 0.890. Test loss: 0.038.Test acc: 0.944\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.181. Acc: 0.951. Test loss: 0.028.Test acc: 0.941\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.100. Acc: 0.962. Test loss: 0.111.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.121. Acc: 0.970. Test loss: 0.002.Test acc: 0.946\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.090. Acc: 0.980. Test loss: 0.004.Test acc: 0.936\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.039. Acc: 0.984. Test loss: 0.466.Test acc: 0.946\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.040. Acc: 0.987. Test loss: 0.002.Test acc: 0.937\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.053. Acc: 0.991. Test loss: 0.000.Test acc: 0.941\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.013. Acc: 0.991. Test loss: 0.002.Test acc: 0.943\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.044. Acc: 0.993. Test loss: 0.007.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.167. Acc: 0.898. Test loss: 0.029.Test acc: 0.945\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.093. Acc: 0.951. Test loss: 0.010.Test acc: 0.950\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.119. Acc: 0.962. Test loss: 0.430.Test acc: 0.949\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.076. Acc: 0.969. Test loss: 0.013.Test acc: 0.939\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.064. Acc: 0.977. Test loss: 0.056.Test acc: 0.945\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.059. Acc: 0.983. Test loss: 0.015.Test acc: 0.942\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.043. Acc: 0.986. Test loss: 0.001.Test acc: 0.945\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.051. Acc: 0.990. Test loss: 0.002.Test acc: 0.942\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.064. Acc: 0.990. Test loss: 0.006.Test acc: 0.938\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.065. Acc: 0.990. Test loss: 0.859.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.203. Acc: 0.939. Test loss: 0.028.Test acc: 0.947\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.120. Acc: 0.955. Test loss: 0.019.Test acc: 0.952\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.115. Acc: 0.965. Test loss: 0.029.Test acc: 0.952\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.109. Acc: 0.973. Test loss: 0.015.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.074. Acc: 0.980. Test loss: 2.047.Test acc: 0.946\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.055. Acc: 0.984. Test loss: 0.001.Test acc: 0.950\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.052. Acc: 0.987. Test loss: 0.000.Test acc: 0.948\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.023. Acc: 0.991. Test loss: 0.001.Test acc: 0.950\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.026. Acc: 0.991. Test loss: 0.000.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.044. Acc: 0.992. Test loss: 0.542.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.204. Acc: 0.927. Test loss: 0.031.Test acc: 0.951\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.133. Acc: 0.956. Test loss: 0.051.Test acc: 0.950\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.113. Acc: 0.965. Test loss: 0.047.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.086. Acc: 0.972. Test loss: 0.205.Test acc: 0.948\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.089. Acc: 0.980. Test loss: 0.016.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.054. Acc: 0.985. Test loss: 1.429.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.051. Acc: 0.987. Test loss: 0.003.Test acc: 0.948\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.047. Acc: 0.989. Test loss: 0.001.Test acc: 0.944\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.060. Acc: 0.992. Test loss: 0.000.Test acc: 0.950\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.022. Acc: 0.994. Test loss: 0.000.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.179. Acc: 0.931. Test loss: 0.019.Test acc: 0.948\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.142. Acc: 0.956. Test loss: 0.017.Test acc: 0.953\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.087. Acc: 0.965. Test loss: 0.025.Test acc: 0.953\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.110. Acc: 0.973. Test loss: 0.027.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.034. Acc: 0.979. Test loss: 0.074.Test acc: 0.952\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.033. Acc: 0.985. Test loss: 0.004.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.033. Acc: 0.988. Test loss: 0.002.Test acc: 0.945\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.032. Acc: 0.991. Test loss: 0.000.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.022. Acc: 0.991. Test loss: 0.123.Test acc: 0.946\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.026. Acc: 0.994. Test loss: 0.458.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.132. Acc: 0.898. Test loss: 0.025.Test acc: 0.945\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.105. Acc: 0.951. Test loss: 0.099.Test acc: 0.949\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.113. Acc: 0.961. Test loss: 0.016.Test acc: 0.944\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.079. Acc: 0.972. Test loss: 0.006.Test acc: 0.941\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.054. Acc: 0.979. Test loss: 0.011.Test acc: 0.940\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.057. Acc: 0.986. Test loss: 0.011.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.018. Acc: 0.989. Test loss: 1.623.Test acc: 0.938\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.030. Acc: 0.990. Test loss: 0.012.Test acc: 0.945\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.030. Acc: 0.992. Test loss: 0.014.Test acc: 0.943\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.006. Acc: 0.993. Test loss: 0.013.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.133. Acc: 0.901. Test loss: 0.557.Test acc: 0.945\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.103. Acc: 0.952. Test loss: 0.146.Test acc: 0.941\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.080. Acc: 0.962. Test loss: 1.135.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.080. Acc: 0.971. Test loss: 0.035.Test acc: 0.948\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.081. Acc: 0.978. Test loss: 1.683.Test acc: 0.941\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.054. Acc: 0.982. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.030. Acc: 0.987. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.034. Acc: 0.991. Test loss: 0.015.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.033. Acc: 0.992. Test loss: 0.020.Test acc: 0.942\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.012. Acc: 0.993. Test loss: 1.737.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.131. Acc: 0.898. Test loss: 0.436.Test acc: 0.945\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.123. Acc: 0.952. Test loss: 0.966.Test acc: 0.943\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.080. Acc: 0.959. Test loss: 0.176.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.095. Acc: 0.969. Test loss: 0.003.Test acc: 0.943\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.038. Acc: 0.977. Test loss: 0.006.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.032. Acc: 0.983. Test loss: 0.000.Test acc: 0.948\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.040. Acc: 0.987. Test loss: 1.306.Test acc: 0.944\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.989. Test loss: 0.249.Test acc: 0.933\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.005. Acc: 0.988. Test loss: 0.000.Test acc: 0.946\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.031. Acc: 0.991. Test loss: 0.038.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.182. Acc: 0.931. Test loss: 0.041.Test acc: 0.949\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.142. Acc: 0.956. Test loss: 0.007.Test acc: 0.951\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.136. Acc: 0.965. Test loss: 0.020.Test acc: 0.952\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.065. Acc: 0.975. Test loss: 0.539.Test acc: 0.951\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.074. Acc: 0.980. Test loss: 0.535.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.035. Acc: 0.985. Test loss: 0.023.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.042. Acc: 0.989. Test loss: 0.012.Test acc: 0.949\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.054. Acc: 0.992. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.040. Acc: 0.992. Test loss: 0.006.Test acc: 0.946\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.016. Acc: 0.993. Test loss: 1.073.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.188. Acc: 0.930. Test loss: 0.152.Test acc: 0.948\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.120. Acc: 0.957. Test loss: 0.279.Test acc: 0.954\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.151. Acc: 0.965. Test loss: 0.008.Test acc: 0.949\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.043. Acc: 0.976. Test loss: 0.002.Test acc: 0.950\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.043. Acc: 0.983. Test loss: 0.010.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.079. Acc: 0.986. Test loss: 0.005.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.043. Acc: 0.989. Test loss: 0.019.Test acc: 0.948\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.031. Acc: 0.990. Test loss: 0.328.Test acc: 0.949\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.038. Acc: 0.994. Test loss: 1.693.Test acc: 0.948\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.015. Acc: 0.994. Test loss: 0.005.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.188. Acc: 0.921. Test loss: 0.032.Test acc: 0.947\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.190. Acc: 0.954. Test loss: 0.225.Test acc: 0.950\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.098. Acc: 0.961. Test loss: 0.076.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.091. Acc: 0.970. Test loss: 0.005.Test acc: 0.948\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.030. Acc: 0.978. Test loss: 0.001.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.031. Acc: 0.987. Test loss: 0.001.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.044. Acc: 0.988. Test loss: 0.001.Test acc: 0.952\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.039. Acc: 0.987. Test loss: 0.000.Test acc: 0.948\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.035. Acc: 0.992. Test loss: 0.005.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.070. Acc: 0.993. Test loss: 0.282.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.185. Acc: 0.899. Test loss: 0.018.Test acc: 0.950\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.115. Acc: 0.957. Test loss: 0.116.Test acc: 0.943\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.097. Acc: 0.966. Test loss: 0.026.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.069. Acc: 0.975. Test loss: 0.017.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.040. Acc: 0.981. Test loss: 0.001.Test acc: 0.941\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.057. Acc: 0.986. Test loss: 0.524.Test acc: 0.936\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.030. Acc: 0.989. Test loss: 0.687.Test acc: 0.941\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.032. Acc: 0.991. Test loss: 0.043.Test acc: 0.939\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.016. Acc: 0.991. Test loss: 0.006.Test acc: 0.943\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.049. Acc: 0.992. Test loss: 0.006.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.160. Acc: 0.890. Test loss: 0.045.Test acc: 0.942\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.105. Acc: 0.954. Test loss: 0.005.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.122. Acc: 0.965. Test loss: 1.055.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.081. Acc: 0.974. Test loss: 0.056.Test acc: 0.939\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.062. Acc: 0.979. Test loss: 0.016.Test acc: 0.949\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.072. Acc: 0.986. Test loss: 0.020.Test acc: 0.938\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.039. Acc: 0.988. Test loss: 0.002.Test acc: 0.944\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.048. Acc: 0.990. Test loss: 0.003.Test acc: 0.938\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.042. Acc: 0.990. Test loss: 0.071.Test acc: 0.941\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.018. Acc: 0.991. Test loss: 0.002.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [44/44]. Loss: 0.208. Acc: 0.885. Test loss: 0.062.Test acc: 0.947\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.131. Acc: 0.954. Test loss: 0.233.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.070. Acc: 0.964. Test loss: 0.405.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.066. Acc: 0.971. Test loss: 0.004.Test acc: 0.944\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.034. Acc: 0.979. Test loss: 0.018.Test acc: 0.939\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.046. Acc: 0.984. Test loss: 0.000.Test acc: 0.943\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.027. Acc: 0.986. Test loss: 1.492.Test acc: 0.941\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.034. Acc: 0.989. Test loss: 0.001.Test acc: 0.940\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.037. Acc: 0.989. Test loss: 2.914.Test acc: 0.943\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.052. Acc: 0.989. Test loss: 0.000.Test acc: 0.936\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.156. Acc: 0.922. Test loss: 0.060.Test acc: 0.950\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.125. Acc: 0.957. Test loss: 0.033.Test acc: 0.952\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.085. Acc: 0.968. Test loss: 0.054.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.099. Acc: 0.974. Test loss: 0.006.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.041. Acc: 0.981. Test loss: 0.526.Test acc: 0.947\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.036. Acc: 0.985. Test loss: 0.001.Test acc: 0.948\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.039. Acc: 0.987. Test loss: 0.113.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.034. Acc: 0.990. Test loss: 1.998.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.034. Acc: 0.991. Test loss: 0.133.Test acc: 0.950\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.019. Acc: 0.993. Test loss: 0.048.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.178. Acc: 0.936. Test loss: 0.028.Test acc: 0.948\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.115. Acc: 0.958. Test loss: 0.230.Test acc: 0.951\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.105. Acc: 0.969. Test loss: 0.011.Test acc: 0.951\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.073. Acc: 0.977. Test loss: 0.019.Test acc: 0.951\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.040. Acc: 0.983. Test loss: 0.073.Test acc: 0.947\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.043. Acc: 0.985. Test loss: 0.017.Test acc: 0.943\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.016. Acc: 0.988. Test loss: 0.011.Test acc: 0.945\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.024. Acc: 0.990. Test loss: 0.416.Test acc: 0.946\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.020. Acc: 0.993. Test loss: 0.000.Test acc: 0.945\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.024. Acc: 0.993. Test loss: 0.000.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.153. Acc: 0.921. Test loss: 0.477.Test acc: 0.950\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.155. Acc: 0.957. Test loss: 0.009.Test acc: 0.953\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.109. Acc: 0.967. Test loss: 0.789.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.088. Acc: 0.976. Test loss: 0.211.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.064. Acc: 0.981. Test loss: 0.270.Test acc: 0.949\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.072. Acc: 0.987. Test loss: 0.000.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.038. Acc: 0.988. Test loss: 0.007.Test acc: 0.943\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.037. Acc: 0.990. Test loss: 0.088.Test acc: 0.945\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.029. Acc: 0.991. Test loss: 0.000.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.026. Acc: 0.991. Test loss: 0.000.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.134. Acc: 0.908. Test loss: 0.358.Test acc: 0.943\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.140. Acc: 0.955. Test loss: 0.095.Test acc: 0.945\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.078. Acc: 0.968. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.087. Acc: 0.978. Test loss: 0.021.Test acc: 0.940\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.061. Acc: 0.983. Test loss: 0.035.Test acc: 0.940\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.042. Acc: 0.986. Test loss: 0.078.Test acc: 0.937\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.019. Acc: 0.989. Test loss: 0.000.Test acc: 0.942\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.024. Acc: 0.990. Test loss: 0.000.Test acc: 0.935\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.029. Acc: 0.991. Test loss: 0.000.Test acc: 0.939\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.016. Acc: 0.992. Test loss: 0.000.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.152. Acc: 0.900. Test loss: 0.127.Test acc: 0.949\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.102. Acc: 0.955. Test loss: 0.005.Test acc: 0.950\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.075. Acc: 0.964. Test loss: 0.012.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.082. Acc: 0.976. Test loss: 1.398.Test acc: 0.941\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.033. Acc: 0.981. Test loss: 0.004.Test acc: 0.946\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.028. Acc: 0.985. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.065. Acc: 0.987. Test loss: 0.048.Test acc: 0.942\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.035. Acc: 0.989. Test loss: 0.000.Test acc: 0.941\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.007. Acc: 0.991. Test loss: 0.002.Test acc: 0.943\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.009. Acc: 0.993. Test loss: 0.000.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.119. Acc: 0.901. Test loss: 0.030.Test acc: 0.944\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.083. Acc: 0.954. Test loss: 0.009.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.078. Acc: 0.964. Test loss: 0.001.Test acc: 0.949\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.050. Acc: 0.973. Test loss: 0.016.Test acc: 0.947\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.040. Acc: 0.979. Test loss: 1.410.Test acc: 0.946\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.068. Acc: 0.985. Test loss: 1.439.Test acc: 0.942\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.018. Acc: 0.988. Test loss: 0.000.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.015. Acc: 0.989. Test loss: 0.000.Test acc: 0.946\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.027. Acc: 0.990. Test loss: 0.099.Test acc: 0.948\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.028. Acc: 0.992. Test loss: 0.000.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.127. Acc: 0.926. Test loss: 0.015.Test acc: 0.949\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.147. Acc: 0.959. Test loss: 0.017.Test acc: 0.951\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.084. Acc: 0.968. Test loss: 0.041.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.058. Acc: 0.977. Test loss: 0.008.Test acc: 0.948\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.060. Acc: 0.982. Test loss: 0.001.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.071. Acc: 0.987. Test loss: 0.022.Test acc: 0.941\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.036. Acc: 0.990. Test loss: 0.000.Test acc: 0.947\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.031. Acc: 0.990. Test loss: 0.614.Test acc: 0.950\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.026. Acc: 0.992. Test loss: 1.032.Test acc: 0.948\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.010. Acc: 0.993. Test loss: 0.001.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.149. Acc: 0.943. Test loss: 0.069.Test acc: 0.950\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.167. Acc: 0.957. Test loss: 0.094.Test acc: 0.953\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.088. Acc: 0.968. Test loss: 0.060.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.057. Acc: 0.975. Test loss: 0.002.Test acc: 0.951\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.058. Acc: 0.982. Test loss: 0.003.Test acc: 0.943\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.084. Acc: 0.985. Test loss: 0.003.Test acc: 0.950\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.028. Acc: 0.988. Test loss: 0.000.Test acc: 0.951\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.053. Acc: 0.990. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.028. Acc: 0.992. Test loss: 0.001.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.021. Acc: 0.993. Test loss: 0.568.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.137. Acc: 0.931. Test loss: 0.271.Test acc: 0.951\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.093. Acc: 0.959. Test loss: 0.328.Test acc: 0.951\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.091. Acc: 0.970. Test loss: 0.732.Test acc: 0.952\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.078. Acc: 0.979. Test loss: 0.001.Test acc: 0.950\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.050. Acc: 0.985. Test loss: 0.015.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.022. Acc: 0.988. Test loss: 0.001.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.035. Acc: 0.991. Test loss: 0.047.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.040. Acc: 0.992. Test loss: 0.078.Test acc: 0.948\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.013. Acc: 0.993. Test loss: 0.000.Test acc: 0.946\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.052. Acc: 0.994. Test loss: 0.155.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.236. Acc: 0.705. Test loss: 0.045.Test acc: 0.934\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.153. Acc: 0.938. Test loss: 0.071.Test acc: 0.939\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.186. Acc: 0.948. Test loss: 0.018.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.194. Acc: 0.951. Test loss: 0.036.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.159. Acc: 0.956. Test loss: 0.012.Test acc: 0.950\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.075. Acc: 0.960. Test loss: 0.615.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.075. Acc: 0.964. Test loss: 0.020.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.133. Acc: 0.968. Test loss: 0.815.Test acc: 0.949\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.103. Acc: 0.972. Test loss: 0.054.Test acc: 0.951\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.103. Acc: 0.977. Test loss: 0.027.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.286. Acc: 0.714. Test loss: 0.495.Test acc: 0.936\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.191. Acc: 0.939. Test loss: 0.039.Test acc: 0.937\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.118. Acc: 0.944. Test loss: 0.021.Test acc: 0.945\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.143. Acc: 0.952. Test loss: 0.013.Test acc: 0.946\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.144. Acc: 0.957. Test loss: 0.072.Test acc: 0.941\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.126. Acc: 0.960. Test loss: 0.007.Test acc: 0.945\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.091. Acc: 0.965. Test loss: 0.011.Test acc: 0.945\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.068. Acc: 0.969. Test loss: 0.501.Test acc: 0.941\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.092. Acc: 0.972. Test loss: 0.009.Test acc: 0.936\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.064. Acc: 0.975. Test loss: 0.942.Test acc: 0.938\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.194. Acc: 0.617. Test loss: 0.039.Test acc: 0.934\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.149. Acc: 0.939. Test loss: 0.036.Test acc: 0.940\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.135. Acc: 0.946. Test loss: 0.102.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.092. Acc: 0.950. Test loss: 0.066.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.126. Acc: 0.955. Test loss: 0.019.Test acc: 0.944\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.114. Acc: 0.958. Test loss: 0.010.Test acc: 0.945\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.139. Acc: 0.964. Test loss: 0.007.Test acc: 0.947\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.080. Acc: 0.967. Test loss: 0.172.Test acc: 0.937\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.115. Acc: 0.971. Test loss: 0.005.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.035. Acc: 0.976. Test loss: 0.016.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.290. Acc: 0.927. Test loss: 0.058.Test acc: 0.933\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.186. Acc: 0.941. Test loss: 0.800.Test acc: 0.943\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.151. Acc: 0.949. Test loss: 0.045.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.115. Acc: 0.956. Test loss: 0.016.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.104. Acc: 0.960. Test loss: 0.018.Test acc: 0.950\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.118. Acc: 0.963. Test loss: 0.155.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.120. Acc: 0.966. Test loss: 0.009.Test acc: 0.953\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.065. Acc: 0.972. Test loss: 0.055.Test acc: 0.952\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.069. Acc: 0.975. Test loss: 0.021.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.050. Acc: 0.979. Test loss: 0.647.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.187. Acc: 0.927. Test loss: 0.436.Test acc: 0.932\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.181. Acc: 0.936. Test loss: 0.035.Test acc: 0.941\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.154. Acc: 0.946. Test loss: 0.028.Test acc: 0.946\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.100. Acc: 0.954. Test loss: 0.724.Test acc: 0.950\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.149. Acc: 0.959. Test loss: 0.047.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.071. Acc: 0.963. Test loss: 0.019.Test acc: 0.953\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.095. Acc: 0.968. Test loss: 0.022.Test acc: 0.950\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.072. Acc: 0.972. Test loss: 0.023.Test acc: 0.948\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.091. Acc: 0.975. Test loss: 0.013.Test acc: 0.951\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.059. Acc: 0.980. Test loss: 0.568.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.231. Acc: 0.930. Test loss: 0.053.Test acc: 0.932\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.198. Acc: 0.938. Test loss: 0.088.Test acc: 0.944\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.150. Acc: 0.949. Test loss: 0.212.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.091. Acc: 0.956. Test loss: 0.014.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.103. Acc: 0.960. Test loss: 0.084.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.082. Acc: 0.964. Test loss: 0.064.Test acc: 0.951\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.067. Acc: 0.969. Test loss: 0.035.Test acc: 0.950\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.111. Acc: 0.971. Test loss: 0.004.Test acc: 0.944\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.066. Acc: 0.975. Test loss: 0.004.Test acc: 0.946\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.054. Acc: 0.978. Test loss: 0.819.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.181. Acc: 0.739. Test loss: 0.125.Test acc: 0.936\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.217. Acc: 0.939. Test loss: 0.203.Test acc: 0.943\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.151. Acc: 0.947. Test loss: 0.892.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.143. Acc: 0.951. Test loss: 0.009.Test acc: 0.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]. Step [44/44]. Loss: 0.116. Acc: 0.957. Test loss: 0.062.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.103. Acc: 0.961. Test loss: 0.005.Test acc: 0.945\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.092. Acc: 0.965. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.092. Acc: 0.969. Test loss: 0.014.Test acc: 0.948\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.058. Acc: 0.974. Test loss: 0.317.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.070. Acc: 0.979. Test loss: 0.007.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.193. Acc: 0.748. Test loss: 0.489.Test acc: 0.935\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.197. Acc: 0.940. Test loss: 0.016.Test acc: 0.941\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.175. Acc: 0.947. Test loss: 0.038.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.149. Acc: 0.953. Test loss: 0.042.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.111. Acc: 0.957. Test loss: 0.007.Test acc: 0.947\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.099. Acc: 0.961. Test loss: 0.706.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.070. Acc: 0.965. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.063. Acc: 0.970. Test loss: 0.001.Test acc: 0.945\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.086. Acc: 0.974. Test loss: 0.008.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.055. Acc: 0.979. Test loss: 0.002.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.203. Acc: 0.736. Test loss: 0.090.Test acc: 0.937\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.150. Acc: 0.941. Test loss: 0.090.Test acc: 0.940\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.123. Acc: 0.948. Test loss: 0.990.Test acc: 0.945\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.083. Acc: 0.953. Test loss: 0.035.Test acc: 0.948\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.118. Acc: 0.959. Test loss: 0.070.Test acc: 0.944\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.128. Acc: 0.963. Test loss: 0.049.Test acc: 0.945\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.116. Acc: 0.968. Test loss: 0.090.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.085. Acc: 0.971. Test loss: 0.134.Test acc: 0.939\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.080. Acc: 0.977. Test loss: 0.359.Test acc: 0.941\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.067. Acc: 0.982. Test loss: 0.002.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.203. Acc: 0.899. Test loss: 0.101.Test acc: 0.938\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.165. Acc: 0.944. Test loss: 0.508.Test acc: 0.946\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.146. Acc: 0.952. Test loss: 0.114.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.146. Acc: 0.956. Test loss: 0.027.Test acc: 0.952\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.117. Acc: 0.961. Test loss: 0.022.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.075. Acc: 0.965. Test loss: 0.005.Test acc: 0.950\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.123. Acc: 0.969. Test loss: 0.008.Test acc: 0.951\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.083. Acc: 0.973. Test loss: 0.013.Test acc: 0.949\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.062. Acc: 0.978. Test loss: 0.278.Test acc: 0.952\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.074. Acc: 0.981. Test loss: 0.259.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.179. Acc: 0.916. Test loss: 0.112.Test acc: 0.936\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.142. Acc: 0.944. Test loss: 0.041.Test acc: 0.947\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.128. Acc: 0.953. Test loss: 0.052.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.150. Acc: 0.958. Test loss: 0.016.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.083. Acc: 0.961. Test loss: 0.007.Test acc: 0.950\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.103. Acc: 0.966. Test loss: 0.029.Test acc: 0.952\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.080. Acc: 0.970. Test loss: 0.005.Test acc: 0.954\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.118. Acc: 0.973. Test loss: 0.008.Test acc: 0.949\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.119. Acc: 0.977. Test loss: 0.056.Test acc: 0.950\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.076. Acc: 0.979. Test loss: 0.002.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.224. Acc: 0.885. Test loss: 0.089.Test acc: 0.935\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.161. Acc: 0.942. Test loss: 0.367.Test acc: 0.945\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.149. Acc: 0.952. Test loss: 0.180.Test acc: 0.947\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.111. Acc: 0.957. Test loss: 0.092.Test acc: 0.949\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.087. Acc: 0.961. Test loss: 0.023.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.105. Acc: 0.964. Test loss: 0.005.Test acc: 0.951\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.080. Acc: 0.968. Test loss: 0.147.Test acc: 0.947\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.114. Acc: 0.971. Test loss: 0.068.Test acc: 0.948\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.078. Acc: 0.976. Test loss: 0.309.Test acc: 0.951\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.111. Acc: 0.980. Test loss: 0.032.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.176. Acc: 0.667. Test loss: 0.034.Test acc: 0.941\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.142. Acc: 0.945. Test loss: 0.018.Test acc: 0.944\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.144. Acc: 0.953. Test loss: 0.113.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.154. Acc: 0.957. Test loss: 0.052.Test acc: 0.943\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.119. Acc: 0.962. Test loss: 0.015.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.115. Acc: 0.969. Test loss: 0.179.Test acc: 0.945\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.089. Acc: 0.974. Test loss: 0.620.Test acc: 0.939\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.044. Acc: 0.980. Test loss: 0.005.Test acc: 0.943\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.091. Acc: 0.985. Test loss: 0.689.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.048. Acc: 0.987. Test loss: 0.002.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.227. Acc: 0.738. Test loss: 0.552.Test acc: 0.943\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.167. Acc: 0.946. Test loss: 0.500.Test acc: 0.946\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.095. Acc: 0.952. Test loss: 0.036.Test acc: 0.948\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.137. Acc: 0.958. Test loss: 0.010.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.111. Acc: 0.962. Test loss: 0.017.Test acc: 0.945\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.102. Acc: 0.968. Test loss: 0.027.Test acc: 0.947\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.073. Acc: 0.973. Test loss: 0.007.Test acc: 0.939\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.081. Acc: 0.979. Test loss: 0.007.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.100. Acc: 0.983. Test loss: 0.039.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.061. Acc: 0.985. Test loss: 0.004.Test acc: 0.937\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.138. Acc: 0.690. Test loss: 0.049.Test acc: 0.940\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.120. Acc: 0.943. Test loss: 0.021.Test acc: 0.940\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.160. Acc: 0.952. Test loss: 0.057.Test acc: 0.945\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.128. Acc: 0.957. Test loss: 0.030.Test acc: 0.944\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.122. Acc: 0.964. Test loss: 0.076.Test acc: 0.945\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.085. Acc: 0.970. Test loss: 0.027.Test acc: 0.939\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.111. Acc: 0.975. Test loss: 0.011.Test acc: 0.942\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.059. Acc: 0.980. Test loss: 0.011.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.047. Acc: 0.984. Test loss: 0.004.Test acc: 0.945\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.104. Acc: 0.986. Test loss: 0.002.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.243. Acc: 0.887. Test loss: 0.571.Test acc: 0.937\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.152. Acc: 0.944. Test loss: 0.031.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.117. Acc: 0.954. Test loss: 0.124.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.103. Acc: 0.961. Test loss: 0.165.Test acc: 0.951\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.084. Acc: 0.966. Test loss: 0.011.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.084. Acc: 0.971. Test loss: 0.249.Test acc: 0.948\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.103. Acc: 0.976. Test loss: 0.003.Test acc: 0.952\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.102. Acc: 0.979. Test loss: 0.136.Test acc: 0.946\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.083. Acc: 0.983. Test loss: 0.018.Test acc: 0.944\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.067. Acc: 0.988. Test loss: 0.004.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.217. Acc: 0.874. Test loss: 0.666.Test acc: 0.934\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.133. Acc: 0.943. Test loss: 0.097.Test acc: 0.946\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.122. Acc: 0.954. Test loss: 0.048.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.121. Acc: 0.961. Test loss: 0.932.Test acc: 0.950\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.128. Acc: 0.967. Test loss: 0.181.Test acc: 0.950\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.169. Acc: 0.970. Test loss: 0.357.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.091. Acc: 0.976. Test loss: 0.005.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.086. Acc: 0.980. Test loss: 0.011.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.071. Acc: 0.986. Test loss: 0.006.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.055. Acc: 0.988. Test loss: 2.015.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.237. Acc: 0.914. Test loss: 0.040.Test acc: 0.937\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.162. Acc: 0.945. Test loss: 0.186.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.109. Acc: 0.955. Test loss: 0.052.Test acc: 0.950\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.121. Acc: 0.960. Test loss: 0.418.Test acc: 0.953\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.152. Acc: 0.966. Test loss: 0.395.Test acc: 0.953\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.095. Acc: 0.970. Test loss: 0.128.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.111. Acc: 0.975. Test loss: 0.015.Test acc: 0.950\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.046. Acc: 0.979. Test loss: 0.066.Test acc: 0.950\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.077. Acc: 0.983. Test loss: 0.013.Test acc: 0.950\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.075. Acc: 0.986. Test loss: 0.008.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.186. Acc: 0.746. Test loss: 0.061.Test acc: 0.941\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.128. Acc: 0.944. Test loss: 0.220.Test acc: 0.944\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.144. Acc: 0.951. Test loss: 0.028.Test acc: 0.945\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.081. Acc: 0.961. Test loss: 0.144.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.115. Acc: 0.964. Test loss: 0.011.Test acc: 0.948\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.058. Acc: 0.969. Test loss: 0.018.Test acc: 0.946\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.050. Acc: 0.975. Test loss: 0.710.Test acc: 0.944\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.044. Acc: 0.981. Test loss: 0.636.Test acc: 0.944\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.048. Acc: 0.984. Test loss: 0.006.Test acc: 0.949\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.059. Acc: 0.987. Test loss: 0.035.Test acc: 0.935\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.186. Acc: 0.757. Test loss: 0.063.Test acc: 0.939\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.181. Acc: 0.944. Test loss: 0.018.Test acc: 0.944\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.183. Acc: 0.951. Test loss: 0.019.Test acc: 0.949\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.136. Acc: 0.956. Test loss: 0.014.Test acc: 0.945\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.085. Acc: 0.963. Test loss: 0.108.Test acc: 0.944\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.064. Acc: 0.968. Test loss: 0.083.Test acc: 0.944\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.050. Acc: 0.972. Test loss: 0.006.Test acc: 0.946\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.053. Acc: 0.980. Test loss: 0.823.Test acc: 0.943\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.046. Acc: 0.983. Test loss: 0.055.Test acc: 0.938\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.040. Acc: 0.987. Test loss: 1.919.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.211. Acc: 0.754. Test loss: 0.691.Test acc: 0.940\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.152. Acc: 0.945. Test loss: 0.066.Test acc: 0.945\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.184. Acc: 0.952. Test loss: 0.036.Test acc: 0.943\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.101. Acc: 0.957. Test loss: 0.791.Test acc: 0.946\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.148. Acc: 0.964. Test loss: 0.870.Test acc: 0.945\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.093. Acc: 0.969. Test loss: 0.004.Test acc: 0.946\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.105. Acc: 0.974. Test loss: 0.607.Test acc: 0.943\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.054. Acc: 0.979. Test loss: 0.036.Test acc: 0.944\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.053. Acc: 0.984. Test loss: 0.004.Test acc: 0.942\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.039. Acc: 0.986. Test loss: 0.255.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.219. Acc: 0.911. Test loss: 0.207.Test acc: 0.941\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.132. Acc: 0.947. Test loss: 0.027.Test acc: 0.949\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.167. Acc: 0.956. Test loss: 0.362.Test acc: 0.951\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.067. Acc: 0.961. Test loss: 0.022.Test acc: 0.953\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.065. Acc: 0.966. Test loss: 0.318.Test acc: 0.952\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.138. Acc: 0.971. Test loss: 0.009.Test acc: 0.948\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.073. Acc: 0.976. Test loss: 1.908.Test acc: 0.952\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.047. Acc: 0.983. Test loss: 0.475.Test acc: 0.951\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.087. Acc: 0.985. Test loss: 0.003.Test acc: 0.950\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.079. Acc: 0.989. Test loss: 0.008.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.153. Acc: 0.928. Test loss: 0.063.Test acc: 0.941\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.153. Acc: 0.947. Test loss: 0.033.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.121. Acc: 0.956. Test loss: 0.029.Test acc: 0.953\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.095. Acc: 0.961. Test loss: 0.005.Test acc: 0.952\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.123. Acc: 0.965. Test loss: 0.765.Test acc: 0.953\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.076. Acc: 0.972. Test loss: 0.006.Test acc: 0.948\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.126. Acc: 0.976. Test loss: 0.077.Test acc: 0.948\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.087. Acc: 0.982. Test loss: 0.001.Test acc: 0.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]. Step [44/44]. Loss: 0.060. Acc: 0.986. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.045. Acc: 0.990. Test loss: 0.252.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Step [44/44]. Loss: 0.204. Acc: 0.933. Test loss: 0.150.Test acc: 0.942\n",
      "Epoch [2/10]. Step [44/44]. Loss: 0.154. Acc: 0.949. Test loss: 0.017.Test acc: 0.948\n",
      "Epoch [3/10]. Step [44/44]. Loss: 0.086. Acc: 0.958. Test loss: 0.536.Test acc: 0.951\n",
      "Epoch [4/10]. Step [44/44]. Loss: 0.113. Acc: 0.963. Test loss: 0.015.Test acc: 0.953\n",
      "Epoch [5/10]. Step [44/44]. Loss: 0.101. Acc: 0.968. Test loss: 0.002.Test acc: 0.951\n",
      "Epoch [6/10]. Step [44/44]. Loss: 0.130. Acc: 0.973. Test loss: 0.005.Test acc: 0.949\n",
      "Epoch [7/10]. Step [44/44]. Loss: 0.076. Acc: 0.979. Test loss: 0.006.Test acc: 0.949\n",
      "Epoch [8/10]. Step [44/44]. Loss: 0.078. Acc: 0.984. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [9/10]. Step [44/44]. Loss: 0.027. Acc: 0.987. Test loss: 0.373.Test acc: 0.947\n",
      "Epoch [10/10]. Step [44/44]. Loss: 0.046. Acc: 0.989. Test loss: 0.874.Test acc: 0.950\n",
      "Finished!\n",
      "CPU times: total: 7h 55min 45s\n",
      "Wall time: 1h 59min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epochs in n_epochs:\n",
    "    for lr in learning_rates:\n",
    "        for embedding_dim in e_dims:\n",
    "            for hidden_dim in h_dims:\n",
    "                for th in ths:\n",
    "                    for dp in dps:\n",
    "                        \n",
    "                        print(f'Hyper params: epochs - {epochs}, learning_rate - {lr}, '\n",
    "                             f'embedding_dim - {embedding_dim}, hidden_dim - {hidden_dim}, '\n",
    "                             f'threshold_level - {th}, drop_prob - {dp}.')\n",
    "                        model = GRUFixedLen(vocab_size=max_words, \n",
    "                                             embedding_dim=embedding_dim, hidden_dim=hidden_dim, \n",
    "                                             drop_prob=dp, use_last=False)\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                        model = model.to(device)\n",
    "                        model.train()\n",
    "                        th = th\n",
    "\n",
    "                        train_loss_history = []\n",
    "                        test_loss_history = []\n",
    "\n",
    "\n",
    "                        for epoch in range(epochs):  \n",
    "                            running_items, running_right = 0.0, 0.0\n",
    "                            for i, data in enumerate(train_loader, 0):\n",
    "                                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                                # обнуляем градиент\n",
    "                                optimizer.zero_grad()\n",
    "                                outputs = model(inputs)\n",
    "\n",
    "                                loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "                                # подсчет ошибки на обучении\n",
    "                                loss = loss.item()\n",
    "                                running_items += len(labels)\n",
    "                                # подсчет метрики на обучении\n",
    "                                pred_labels = torch.squeeze((outputs > th).int())\n",
    "                                running_right += (labels == pred_labels).sum()\n",
    "\n",
    "                            # выводим статистику о процессе обучения\n",
    "                            model.eval()\n",
    "\n",
    "                            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "                                    f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                                    f'Loss: {loss:.3f}. ' \\\n",
    "                                    f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "                            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "                            train_loss_history.append(loss)\n",
    "\n",
    "                                # выводим статистику на тестовых данных\n",
    "                            test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "                            for j, data in enumerate(val_loader):\n",
    "                                test_labels = data[1].to(device)\n",
    "                                test_outputs = model(data[0].to(device))\n",
    "\n",
    "                                # подсчет ошибки на тесте\n",
    "                                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "                                # подсчет метрики на тесте\n",
    "                                test_running_total += len(data[1])\n",
    "                                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "                                test_running_right += (test_labels == pred_test_labels).sum()\n",
    "\n",
    "                            test_loss_history.append(test_loss.item())\n",
    "                            print(f'Test loss: {test_loss:.3f}.' \n",
    "                                  f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "                            model.train()\n",
    "\n",
    "                        print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d1cff",
   "metadata": {},
   "source": [
    "По результатам обучения мы получили на 5 эпохах лучшие параметры accuracy 99% на трейне и 95,2% на тесте; на 10 эпохах немного хуже: на трейне - 98,9% и 95% - на тесте. Сами по себе чистые результаты оказались довольно близки и граница сильно размыта, что в свою очередь затрудняет тонкие настройки модели в чистом виде."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191d3543",
   "metadata": {},
   "source": [
    "Инициализируем и обучим сеть LSTM на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "269a09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
    "        super().__init__()\n",
    "        self.use_last = use_last\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "#         self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "#         x = self.dropout(x)\n",
    "        lstm_out, ht = self.lstm(x)\n",
    "       \n",
    "        if self.use_last:\n",
    "            last_tensor = lstm_out[:,-1,:]\n",
    "        else:\n",
    "            # use mean\n",
    "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
    "    \n",
    "        out = self.linear(last_tensor)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3554808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.178. Acc: 0.875. Test loss: 0.027.Test acc: 0.926\n",
      "Epoch [2/5]. Loss: 0.148. Acc: 0.948. Test loss: 0.606.Test acc: 0.946\n",
      "Epoch [3/5]. Loss: 0.108. Acc: 0.957. Test loss: 0.027.Test acc: 0.946\n",
      "Epoch [4/5]. Loss: 0.095. Acc: 0.965. Test loss: 0.122.Test acc: 0.945\n",
      "Epoch [5/5]. Loss: 0.083. Acc: 0.969. Test loss: 1.261.Test acc: 0.940\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.253. Acc: 0.870. Test loss: 0.112.Test acc: 0.928\n",
      "Epoch [2/5]. Loss: 0.209. Acc: 0.942. Test loss: 0.011.Test acc: 0.946\n",
      "Epoch [3/5]. Loss: 0.132. Acc: 0.953. Test loss: 0.083.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.116. Acc: 0.960. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.108. Acc: 0.965. Test loss: 0.002.Test acc: 0.928\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.235. Acc: 0.862. Test loss: 0.040.Test acc: 0.907\n",
      "Epoch [2/5]. Loss: 0.206. Acc: 0.913. Test loss: 0.208.Test acc: 0.915\n",
      "Epoch [3/5]. Loss: 0.185. Acc: 0.934. Test loss: 0.228.Test acc: 0.933\n",
      "Epoch [4/5]. Loss: 0.148. Acc: 0.947. Test loss: 0.270.Test acc: 0.937\n",
      "Epoch [5/5]. Loss: 0.098. Acc: 0.951. Test loss: 0.016.Test acc: 0.937\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.197. Acc: 0.933. Test loss: 0.030.Test acc: 0.944\n",
      "Epoch [2/5]. Loss: 0.151. Acc: 0.951. Test loss: 0.142.Test acc: 0.946\n",
      "Epoch [3/5]. Loss: 0.098. Acc: 0.960. Test loss: 0.040.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.099. Acc: 0.966. Test loss: 1.463.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.103. Acc: 0.972. Test loss: 0.031.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.196. Acc: 0.935. Test loss: 0.093.Test acc: 0.945\n",
      "Epoch [2/5]. Loss: 0.154. Acc: 0.951. Test loss: 0.028.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.130. Acc: 0.958. Test loss: 0.008.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.087. Acc: 0.966. Test loss: 0.055.Test acc: 0.950\n",
      "Epoch [5/5]. Loss: 0.073. Acc: 0.971. Test loss: 0.095.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.168. Acc: 0.910. Test loss: 0.187.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.196. Acc: 0.941. Test loss: 0.115.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.168. Acc: 0.950. Test loss: 0.552.Test acc: 0.947\n",
      "Epoch [4/5]. Loss: 0.141. Acc: 0.961. Test loss: 0.020.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.098. Acc: 0.966. Test loss: 0.021.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.170. Acc: 0.895. Test loss: 0.057.Test acc: 0.943\n",
      "Epoch [2/5]. Loss: 0.136. Acc: 0.950. Test loss: 0.026.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.114. Acc: 0.959. Test loss: 0.047.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.128. Acc: 0.967. Test loss: 0.094.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.077. Acc: 0.972. Test loss: 0.002.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.167. Acc: 0.899. Test loss: 0.395.Test acc: 0.936\n",
      "Epoch [2/5]. Loss: 0.134. Acc: 0.947. Test loss: 0.133.Test acc: 0.937\n",
      "Epoch [3/5]. Loss: 0.119. Acc: 0.955. Test loss: 0.010.Test acc: 0.940\n",
      "Epoch [4/5]. Loss: 0.087. Acc: 0.964. Test loss: 0.425.Test acc: 0.946\n",
      "Epoch [5/5]. Loss: 0.077. Acc: 0.972. Test loss: 0.017.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.134. Acc: 0.896. Test loss: 0.036.Test acc: 0.936\n",
      "Epoch [2/5]. Loss: 0.189. Acc: 0.947. Test loss: 0.681.Test acc: 0.950\n",
      "Epoch [3/5]. Loss: 0.081. Acc: 0.955. Test loss: 0.091.Test acc: 0.941\n",
      "Epoch [4/5]. Loss: 0.104. Acc: 0.962. Test loss: 0.289.Test acc: 0.942\n",
      "Epoch [5/5]. Loss: 0.105. Acc: 0.969. Test loss: 0.001.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.142. Acc: 0.934. Test loss: 0.034.Test acc: 0.945\n",
      "Epoch [2/5]. Loss: 0.123. Acc: 0.953. Test loss: 0.568.Test acc: 0.951\n",
      "Epoch [3/5]. Loss: 0.134. Acc: 0.960. Test loss: 0.682.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.087. Acc: 0.968. Test loss: 0.008.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.075. Acc: 0.974. Test loss: 1.569.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.176. Acc: 0.927. Test loss: 0.122.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.169. Acc: 0.943. Test loss: 0.055.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.121. Acc: 0.957. Test loss: 0.019.Test acc: 0.950\n",
      "Epoch [4/5]. Loss: 0.119. Acc: 0.965. Test loss: 0.449.Test acc: 0.951\n",
      "Epoch [5/5]. Loss: 0.117. Acc: 0.971. Test loss: 0.028.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.228. Acc: 0.913. Test loss: 1.155.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.213. Acc: 0.943. Test loss: 0.077.Test acc: 0.950\n",
      "Epoch [3/5]. Loss: 0.159. Acc: 0.956. Test loss: 0.050.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.102. Acc: 0.963. Test loss: 0.042.Test acc: 0.951\n",
      "Epoch [5/5]. Loss: 0.115. Acc: 0.968. Test loss: 0.173.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.206. Acc: 0.880. Test loss: 0.033.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.194. Acc: 0.933. Test loss: 0.022.Test acc: 0.929\n",
      "Epoch [3/5]. Loss: 0.138. Acc: 0.941. Test loss: 0.035.Test acc: 0.936\n",
      "Epoch [4/5]. Loss: 0.142. Acc: 0.951. Test loss: 0.103.Test acc: 0.938\n",
      "Epoch [5/5]. Loss: 0.090. Acc: 0.961. Test loss: 0.681.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.231. Acc: 0.878. Test loss: 0.035.Test acc: 0.941\n",
      "Epoch [2/5]. Loss: 0.111. Acc: 0.949. Test loss: 0.025.Test acc: 0.945\n",
      "Epoch [3/5]. Loss: 0.152. Acc: 0.960. Test loss: 0.007.Test acc: 0.950\n",
      "Epoch [4/5]. Loss: 0.115. Acc: 0.968. Test loss: 0.274.Test acc: 0.948\n",
      "Epoch [5/5]. Loss: 0.071. Acc: 0.974. Test loss: 0.013.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.206. Acc: 0.864. Test loss: 0.073.Test acc: 0.908\n",
      "Epoch [2/5]. Loss: 0.180. Acc: 0.913. Test loss: 0.043.Test acc: 0.924\n",
      "Epoch [3/5]. Loss: 0.155. Acc: 0.926. Test loss: 0.357.Test acc: 0.902\n",
      "Epoch [4/5]. Loss: 0.094. Acc: 0.941. Test loss: 0.010.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.103. Acc: 0.954. Test loss: 0.621.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.185. Acc: 0.930. Test loss: 0.036.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.150. Acc: 0.935. Test loss: 0.118.Test acc: 0.938\n",
      "Epoch [3/5]. Loss: 0.134. Acc: 0.951. Test loss: 0.047.Test acc: 0.948\n",
      "Epoch [4/5]. Loss: 0.119. Acc: 0.962. Test loss: 0.095.Test acc: 0.952\n",
      "Epoch [5/5]. Loss: 0.072. Acc: 0.971. Test loss: 0.006.Test acc: 0.953\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.184. Acc: 0.930. Test loss: 0.065.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.216. Acc: 0.945. Test loss: 0.044.Test acc: 0.947\n",
      "Epoch [3/5]. Loss: 0.114. Acc: 0.957. Test loss: 0.109.Test acc: 0.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]. Loss: 0.081. Acc: 0.966. Test loss: 0.013.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.087. Acc: 0.973. Test loss: 0.005.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.150. Acc: 0.921. Test loss: 0.181.Test acc: 0.944\n",
      "Epoch [2/5]. Loss: 0.196. Acc: 0.949. Test loss: 0.055.Test acc: 0.947\n",
      "Epoch [3/5]. Loss: 0.184. Acc: 0.961. Test loss: 0.009.Test acc: 0.953\n",
      "Epoch [4/5]. Loss: 0.125. Acc: 0.967. Test loss: 0.014.Test acc: 0.954\n",
      "Epoch [5/5]. Loss: 0.113. Acc: 0.974. Test loss: 0.057.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.120. Acc: 0.896. Test loss: 0.026.Test acc: 0.941\n",
      "Epoch [2/5]. Loss: 0.102. Acc: 0.948. Test loss: 0.588.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.137. Acc: 0.958. Test loss: 0.255.Test acc: 0.946\n",
      "Epoch [4/5]. Loss: 0.060. Acc: 0.967. Test loss: 0.113.Test acc: 0.932\n",
      "Epoch [5/5]. Loss: 0.084. Acc: 0.973. Test loss: 0.010.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.224. Acc: 0.891. Test loss: 0.024.Test acc: 0.943\n",
      "Epoch [2/5]. Loss: 0.138. Acc: 0.945. Test loss: 0.193.Test acc: 0.946\n",
      "Epoch [3/5]. Loss: 0.060. Acc: 0.956. Test loss: 0.033.Test acc: 0.950\n",
      "Epoch [4/5]. Loss: 0.071. Acc: 0.966. Test loss: 1.285.Test acc: 0.946\n",
      "Epoch [5/5]. Loss: 0.071. Acc: 0.974. Test loss: 0.001.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.210. Acc: 0.879. Test loss: 0.139.Test acc: 0.871\n",
      "Epoch [2/5]. Loss: 0.152. Acc: 0.927. Test loss: 1.035.Test acc: 0.947\n",
      "Epoch [3/5]. Loss: 0.147. Acc: 0.952. Test loss: 0.099.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.096. Acc: 0.959. Test loss: 0.001.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.083. Acc: 0.967. Test loss: 0.076.Test acc: 0.936\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.139. Acc: 0.939. Test loss: 0.548.Test acc: 0.944\n",
      "Epoch [2/5]. Loss: 0.149. Acc: 0.953. Test loss: 0.030.Test acc: 0.950\n",
      "Epoch [3/5]. Loss: 0.104. Acc: 0.961. Test loss: 0.010.Test acc: 0.952\n",
      "Epoch [4/5]. Loss: 0.104. Acc: 0.968. Test loss: 0.368.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.066. Acc: 0.974. Test loss: 0.000.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.198. Acc: 0.920. Test loss: 0.435.Test acc: 0.947\n",
      "Epoch [2/5]. Loss: 0.100. Acc: 0.954. Test loss: 0.038.Test acc: 0.951\n",
      "Epoch [3/5]. Loss: 0.089. Acc: 0.965. Test loss: 0.035.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.084. Acc: 0.972. Test loss: 0.003.Test acc: 0.950\n",
      "Epoch [5/5]. Loss: 0.073. Acc: 0.978. Test loss: 0.051.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.173. Acc: 0.909. Test loss: 0.035.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.147. Acc: 0.937. Test loss: 0.126.Test acc: 0.931\n",
      "Epoch [3/5]. Loss: 0.136. Acc: 0.948. Test loss: 0.072.Test acc: 0.945\n",
      "Epoch [4/5]. Loss: 0.100. Acc: 0.958. Test loss: 0.406.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.115. Acc: 0.965. Test loss: 0.003.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.253. Acc: 0.589. Test loss: 0.047.Test acc: 0.932\n",
      "Epoch [2/5]. Loss: 0.113. Acc: 0.936. Test loss: 0.040.Test acc: 0.938\n",
      "Epoch [3/5]. Loss: 0.152. Acc: 0.943. Test loss: 0.149.Test acc: 0.931\n",
      "Epoch [4/5]. Loss: 0.155. Acc: 0.949. Test loss: 0.025.Test acc: 0.941\n",
      "Epoch [5/5]. Loss: 0.085. Acc: 0.956. Test loss: 0.009.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.239. Acc: 0.553. Test loss: 0.043.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.168. Acc: 0.938. Test loss: 0.780.Test acc: 0.932\n",
      "Epoch [3/5]. Loss: 0.161. Acc: 0.942. Test loss: 0.458.Test acc: 0.937\n",
      "Epoch [4/5]. Loss: 0.167. Acc: 0.950. Test loss: 0.017.Test acc: 0.942\n",
      "Epoch [5/5]. Loss: 0.118. Acc: 0.955. Test loss: 0.029.Test acc: 0.940\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.263. Acc: 0.619. Test loss: 0.055.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.196. Acc: 0.938. Test loss: 0.026.Test acc: 0.934\n",
      "Epoch [3/5]. Loss: 0.131. Acc: 0.941. Test loss: 0.120.Test acc: 0.938\n",
      "Epoch [4/5]. Loss: 0.171. Acc: 0.950. Test loss: 0.099.Test acc: 0.942\n",
      "Epoch [5/5]. Loss: 0.127. Acc: 0.957. Test loss: 0.146.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.253. Acc: 0.890. Test loss: 0.039.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.196. Acc: 0.936. Test loss: 0.280.Test acc: 0.939\n",
      "Epoch [3/5]. Loss: 0.129. Acc: 0.948. Test loss: 0.169.Test acc: 0.946\n",
      "Epoch [4/5]. Loss: 0.107. Acc: 0.954. Test loss: 0.106.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.084. Acc: 0.960. Test loss: 0.142.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.162. Acc: 0.919. Test loss: 0.052.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.183. Acc: 0.935. Test loss: 0.043.Test acc: 0.944\n",
      "Epoch [3/5]. Loss: 0.185. Acc: 0.946. Test loss: 0.725.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.130. Acc: 0.954. Test loss: 0.688.Test acc: 0.952\n",
      "Epoch [5/5]. Loss: 0.115. Acc: 0.961. Test loss: 0.478.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.223. Acc: 0.930. Test loss: 0.585.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.175. Acc: 0.936. Test loss: 0.044.Test acc: 0.942\n",
      "Epoch [3/5]. Loss: 0.154. Acc: 0.947. Test loss: 0.032.Test acc: 0.948\n",
      "Epoch [4/5]. Loss: 0.095. Acc: 0.954. Test loss: 0.067.Test acc: 0.950\n",
      "Epoch [5/5]. Loss: 0.135. Acc: 0.959. Test loss: 0.013.Test acc: 0.952\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.200. Acc: 0.662. Test loss: 0.435.Test acc: 0.935\n",
      "Epoch [2/5]. Loss: 0.187. Acc: 0.938. Test loss: 0.613.Test acc: 0.936\n",
      "Epoch [3/5]. Loss: 0.141. Acc: 0.946. Test loss: 0.018.Test acc: 0.941\n",
      "Epoch [4/5]. Loss: 0.122. Acc: 0.953. Test loss: 0.007.Test acc: 0.945\n",
      "Epoch [5/5]. Loss: 0.126. Acc: 0.959. Test loss: 0.835.Test acc: 0.936\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.226. Acc: 0.671. Test loss: 0.086.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.207. Acc: 0.937. Test loss: 0.032.Test acc: 0.939\n",
      "Epoch [3/5]. Loss: 0.093. Acc: 0.946. Test loss: 0.129.Test acc: 0.944\n",
      "Epoch [4/5]. Loss: 0.204. Acc: 0.953. Test loss: 0.030.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.136. Acc: 0.958. Test loss: 0.022.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.224. Acc: 0.642. Test loss: 0.055.Test acc: 0.936\n",
      "Epoch [2/5]. Loss: 0.165. Acc: 0.938. Test loss: 0.036.Test acc: 0.941\n",
      "Epoch [3/5]. Loss: 0.141. Acc: 0.945. Test loss: 0.031.Test acc: 0.942\n",
      "Epoch [4/5]. Loss: 0.122. Acc: 0.951. Test loss: 0.024.Test acc: 0.944\n",
      "Epoch [5/5]. Loss: 0.177. Acc: 0.957. Test loss: 0.039.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.227. Acc: 0.890. Test loss: 0.075.Test acc: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]. Loss: 0.192. Acc: 0.940. Test loss: 0.029.Test acc: 0.944\n",
      "Epoch [3/5]. Loss: 0.173. Acc: 0.950. Test loss: 0.016.Test acc: 0.947\n",
      "Epoch [4/5]. Loss: 0.183. Acc: 0.957. Test loss: 0.072.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.102. Acc: 0.961. Test loss: 0.005.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.216. Acc: 0.930. Test loss: 0.131.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.170. Acc: 0.942. Test loss: 0.117.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.127. Acc: 0.952. Test loss: 0.080.Test acc: 0.948\n",
      "Epoch [4/5]. Loss: 0.086. Acc: 0.958. Test loss: 0.718.Test acc: 0.950\n",
      "Epoch [5/5]. Loss: 0.118. Acc: 0.962. Test loss: 0.030.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.243. Acc: 0.930. Test loss: 0.065.Test acc: 0.932\n",
      "Epoch [2/5]. Loss: 0.233. Acc: 0.941. Test loss: 0.240.Test acc: 0.944\n",
      "Epoch [3/5]. Loss: 0.111. Acc: 0.949. Test loss: 0.043.Test acc: 0.946\n",
      "Epoch [4/5]. Loss: 0.137. Acc: 0.955. Test loss: 0.013.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.120. Acc: 0.960. Test loss: 0.025.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.256. Acc: 0.525. Test loss: 0.620.Test acc: 0.934\n",
      "Epoch [2/5]. Loss: 0.178. Acc: 0.942. Test loss: 0.030.Test acc: 0.939\n",
      "Epoch [3/5]. Loss: 0.120. Acc: 0.947. Test loss: 0.014.Test acc: 0.941\n",
      "Epoch [4/5]. Loss: 0.098. Acc: 0.955. Test loss: 0.575.Test acc: 0.950\n",
      "Epoch [5/5]. Loss: 0.138. Acc: 0.963. Test loss: 1.016.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.271. Acc: 0.557. Test loss: 0.282.Test acc: 0.935\n",
      "Epoch [2/5]. Loss: 0.140. Acc: 0.940. Test loss: 0.039.Test acc: 0.938\n",
      "Epoch [3/5]. Loss: 0.134. Acc: 0.945. Test loss: 0.042.Test acc: 0.937\n",
      "Epoch [4/5]. Loss: 0.119. Acc: 0.955. Test loss: 0.095.Test acc: 0.945\n",
      "Epoch [5/5]. Loss: 0.130. Acc: 0.963. Test loss: 0.996.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.193. Acc: 0.555. Test loss: 0.041.Test acc: 0.933\n",
      "Epoch [2/5]. Loss: 0.200. Acc: 0.940. Test loss: 0.024.Test acc: 0.941\n",
      "Epoch [3/5]. Loss: 0.161. Acc: 0.947. Test loss: 0.207.Test acc: 0.942\n",
      "Epoch [4/5]. Loss: 0.120. Acc: 0.957. Test loss: 0.063.Test acc: 0.947\n",
      "Epoch [5/5]. Loss: 0.111. Acc: 0.964. Test loss: 0.842.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.235. Acc: 0.825. Test loss: 0.052.Test acc: 0.933\n",
      "Epoch [2/5]. Loss: 0.182. Acc: 0.940. Test loss: 0.109.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.114. Acc: 0.952. Test loss: 0.026.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.103. Acc: 0.960. Test loss: 0.191.Test acc: 0.949\n",
      "Epoch [5/5]. Loss: 0.151. Acc: 0.966. Test loss: 0.066.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.217. Acc: 0.930. Test loss: 0.034.Test acc: 0.930\n",
      "Epoch [2/5]. Loss: 0.143. Acc: 0.939. Test loss: 0.126.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.192. Acc: 0.952. Test loss: 0.011.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.102. Acc: 0.959. Test loss: 0.589.Test acc: 0.948\n",
      "Epoch [5/5]. Loss: 0.077. Acc: 0.966. Test loss: 0.008.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.249. Acc: 0.930. Test loss: 0.308.Test acc: 0.932\n",
      "Epoch [2/5]. Loss: 0.187. Acc: 0.941. Test loss: 0.023.Test acc: 0.947\n",
      "Epoch [3/5]. Loss: 0.128. Acc: 0.953. Test loss: 0.080.Test acc: 0.951\n",
      "Epoch [4/5]. Loss: 0.150. Acc: 0.960. Test loss: 0.037.Test acc: 0.951\n",
      "Epoch [5/5]. Loss: 0.118. Acc: 0.965. Test loss: 0.036.Test acc: 0.953\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.219. Acc: 0.662. Test loss: 0.065.Test acc: 0.939\n",
      "Epoch [2/5]. Loss: 0.186. Acc: 0.942. Test loss: 0.127.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.182. Acc: 0.951. Test loss: 0.260.Test acc: 0.949\n",
      "Epoch [4/5]. Loss: 0.085. Acc: 0.960. Test loss: 0.136.Test acc: 0.948\n",
      "Epoch [5/5]. Loss: 0.095. Acc: 0.966. Test loss: 0.043.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.171. Acc: 0.687. Test loss: 0.593.Test acc: 0.942\n",
      "Epoch [2/5]. Loss: 0.136. Acc: 0.942. Test loss: 0.165.Test acc: 0.944\n",
      "Epoch [3/5]. Loss: 0.133. Acc: 0.952. Test loss: 0.011.Test acc: 0.948\n",
      "Epoch [4/5]. Loss: 0.095. Acc: 0.959. Test loss: 0.014.Test acc: 0.944\n",
      "Epoch [5/5]. Loss: 0.105. Acc: 0.964. Test loss: 0.738.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.267. Acc: 0.649. Test loss: 0.064.Test acc: 0.939\n",
      "Epoch [2/5]. Loss: 0.130. Acc: 0.940. Test loss: 0.053.Test acc: 0.943\n",
      "Epoch [3/5]. Loss: 0.147. Acc: 0.951. Test loss: 0.610.Test acc: 0.942\n",
      "Epoch [4/5]. Loss: 0.118. Acc: 0.957. Test loss: 0.018.Test acc: 0.942\n",
      "Epoch [5/5]. Loss: 0.089. Acc: 0.964. Test loss: 0.005.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/5]. Loss: 0.205. Acc: 0.870. Test loss: 0.070.Test acc: 0.939\n",
      "Epoch [2/5]. Loss: 0.160. Acc: 0.945. Test loss: 0.244.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.102. Acc: 0.955. Test loss: 0.020.Test acc: 0.950\n",
      "Epoch [4/5]. Loss: 0.115. Acc: 0.963. Test loss: 0.027.Test acc: 0.951\n",
      "Epoch [5/5]. Loss: 0.145. Acc: 0.966. Test loss: 0.015.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/5]. Loss: 0.158. Acc: 0.869. Test loss: 0.054.Test acc: 0.939\n",
      "Epoch [2/5]. Loss: 0.155. Acc: 0.945. Test loss: 0.026.Test acc: 0.947\n",
      "Epoch [3/5]. Loss: 0.118. Acc: 0.956. Test loss: 0.028.Test acc: 0.950\n",
      "Epoch [4/5]. Loss: 0.114. Acc: 0.962. Test loss: 0.110.Test acc: 0.951\n",
      "Epoch [5/5]. Loss: 0.115. Acc: 0.967. Test loss: 0.023.Test acc: 0.953\n",
      "Finished!\n",
      "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/5]. Loss: 0.230. Acc: 0.870. Test loss: 0.066.Test acc: 0.936\n",
      "Epoch [2/5]. Loss: 0.135. Acc: 0.944. Test loss: 0.830.Test acc: 0.948\n",
      "Epoch [3/5]. Loss: 0.191. Acc: 0.955. Test loss: 0.022.Test acc: 0.952\n",
      "Epoch [4/5]. Loss: 0.118. Acc: 0.961. Test loss: 0.020.Test acc: 0.952\n",
      "Epoch [5/5]. Loss: 0.066. Acc: 0.967. Test loss: 0.006.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.199. Acc: 0.870. Test loss: 0.041.Test acc: 0.927\n",
      "Epoch [2/10]. Loss: 0.148. Acc: 0.932. Test loss: 0.164.Test acc: 0.922\n",
      "Epoch [3/10]. Loss: 0.175. Acc: 0.939. Test loss: 0.011.Test acc: 0.942\n",
      "Epoch [4/10]. Loss: 0.158. Acc: 0.951. Test loss: 0.074.Test acc: 0.940\n",
      "Epoch [5/10]. Loss: 0.136. Acc: 0.956. Test loss: 0.305.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.071. Acc: 0.962. Test loss: 0.002.Test acc: 0.946\n",
      "Epoch [7/10]. Loss: 0.081. Acc: 0.966. Test loss: 0.031.Test acc: 0.949\n",
      "Epoch [8/10]. Loss: 0.081. Acc: 0.974. Test loss: 0.009.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.059. Acc: 0.980. Test loss: 0.708.Test acc: 0.935\n",
      "Epoch [10/10]. Loss: 0.089. Acc: 0.985. Test loss: 0.028.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.234. Acc: 0.869. Test loss: 0.651.Test acc: 0.925\n",
      "Epoch [2/10]. Loss: 0.201. Acc: 0.926. Test loss: 0.175.Test acc: 0.934\n",
      "Epoch [3/10]. Loss: 0.168. Acc: 0.940. Test loss: 0.089.Test acc: 0.943\n",
      "Epoch [4/10]. Loss: 0.130. Acc: 0.952. Test loss: 0.012.Test acc: 0.944\n",
      "Epoch [5/10]. Loss: 0.094. Acc: 0.958. Test loss: 0.230.Test acc: 0.945\n",
      "Epoch [6/10]. Loss: 0.083. Acc: 0.964. Test loss: 0.015.Test acc: 0.945\n",
      "Epoch [7/10]. Loss: 0.072. Acc: 0.966. Test loss: 0.001.Test acc: 0.943\n",
      "Epoch [8/10]. Loss: 0.077. Acc: 0.970. Test loss: 0.024.Test acc: 0.938\n",
      "Epoch [9/10]. Loss: 0.049. Acc: 0.975. Test loss: 0.005.Test acc: 0.936\n",
      "Epoch [10/10]. Loss: 0.043. Acc: 0.982. Test loss: 0.043.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.165. Acc: 0.868. Test loss: 0.041.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.144. Acc: 0.942. Test loss: 0.019.Test acc: 0.945\n",
      "Epoch [3/10]. Loss: 0.105. Acc: 0.952. Test loss: 0.031.Test acc: 0.947\n",
      "Epoch [4/10]. Loss: 0.120. Acc: 0.959. Test loss: 0.116.Test acc: 0.945\n",
      "Epoch [5/10]. Loss: 0.083. Acc: 0.965. Test loss: 0.033.Test acc: 0.939\n",
      "Epoch [6/10]. Loss: 0.062. Acc: 0.974. Test loss: 0.613.Test acc: 0.944\n",
      "Epoch [7/10]. Loss: 0.047. Acc: 0.979. Test loss: 0.003.Test acc: 0.941\n",
      "Epoch [8/10]. Loss: 0.037. Acc: 0.985. Test loss: 0.000.Test acc: 0.938\n",
      "Epoch [9/10]. Loss: 0.035. Acc: 0.986. Test loss: 0.048.Test acc: 0.940\n",
      "Epoch [10/10]. Loss: 0.049. Acc: 0.988. Test loss: 0.501.Test acc: 0.938\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.187. Acc: 0.938. Test loss: 0.099.Test acc: 0.945\n",
      "Epoch [2/10]. Loss: 0.150. Acc: 0.949. Test loss: 0.158.Test acc: 0.950\n",
      "Epoch [3/10]. Loss: 0.187. Acc: 0.959. Test loss: 0.008.Test acc: 0.949\n",
      "Epoch [4/10]. Loss: 0.113. Acc: 0.967. Test loss: 0.004.Test acc: 0.951\n",
      "Epoch [5/10]. Loss: 0.101. Acc: 0.973. Test loss: 0.007.Test acc: 0.948\n",
      "Epoch [6/10]. Loss: 0.126. Acc: 0.977. Test loss: 0.304.Test acc: 0.947\n",
      "Epoch [7/10]. Loss: 0.048. Acc: 0.982. Test loss: 0.024.Test acc: 0.946\n",
      "Epoch [8/10]. Loss: 0.051. Acc: 0.983. Test loss: 0.150.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.058. Acc: 0.987. Test loss: 0.410.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.022. Acc: 0.991. Test loss: 0.055.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.246. Acc: 0.931. Test loss: 0.051.Test acc: 0.942\n",
      "Epoch [2/10]. Loss: 0.115. Acc: 0.945. Test loss: 0.017.Test acc: 0.947\n",
      "Epoch [3/10]. Loss: 0.107. Acc: 0.956. Test loss: 0.060.Test acc: 0.951\n",
      "Epoch [4/10]. Loss: 0.109. Acc: 0.964. Test loss: 0.005.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.104. Acc: 0.968. Test loss: 0.004.Test acc: 0.951\n",
      "Epoch [6/10]. Loss: 0.111. Acc: 0.973. Test loss: 0.082.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.093. Acc: 0.977. Test loss: 0.119.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.032. Acc: 0.980. Test loss: 0.000.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.047. Acc: 0.984. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [10/10]. Loss: 0.069. Acc: 0.987. Test loss: 0.002.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.158. Acc: 0.914. Test loss: 0.036.Test acc: 0.936\n",
      "Epoch [2/10]. Loss: 0.161. Acc: 0.949. Test loss: 0.008.Test acc: 0.948\n",
      "Epoch [3/10]. Loss: 0.119. Acc: 0.958. Test loss: 0.043.Test acc: 0.949\n",
      "Epoch [4/10]. Loss: 0.126. Acc: 0.964. Test loss: 0.709.Test acc: 0.953\n",
      "Epoch [5/10]. Loss: 0.101. Acc: 0.970. Test loss: 0.005.Test acc: 0.950\n",
      "Epoch [6/10]. Loss: 0.049. Acc: 0.974. Test loss: 0.007.Test acc: 0.949\n",
      "Epoch [7/10]. Loss: 0.055. Acc: 0.977. Test loss: 0.160.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.066. Acc: 0.981. Test loss: 0.310.Test acc: 0.947\n",
      "Epoch [9/10]. Loss: 0.056. Acc: 0.984. Test loss: 0.003.Test acc: 0.947\n",
      "Epoch [10/10]. Loss: 0.051. Acc: 0.988. Test loss: 0.026.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.244. Acc: 0.894. Test loss: 0.032.Test acc: 0.943\n",
      "Epoch [2/10]. Loss: 0.162. Acc: 0.942. Test loss: 0.035.Test acc: 0.945\n",
      "Epoch [3/10]. Loss: 0.133. Acc: 0.953. Test loss: 0.006.Test acc: 0.939\n",
      "Epoch [4/10]. Loss: 0.146. Acc: 0.960. Test loss: 0.017.Test acc: 0.940\n",
      "Epoch [5/10]. Loss: 0.086. Acc: 0.966. Test loss: 0.002.Test acc: 0.938\n",
      "Epoch [6/10]. Loss: 0.101. Acc: 0.971. Test loss: 0.030.Test acc: 0.943\n",
      "Epoch [7/10]. Loss: 0.071. Acc: 0.978. Test loss: 1.476.Test acc: 0.939\n",
      "Epoch [8/10]. Loss: 0.061. Acc: 0.983. Test loss: 0.003.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.061. Acc: 0.985. Test loss: 0.000.Test acc: 0.936\n",
      "Epoch [10/10]. Loss: 0.042. Acc: 0.989. Test loss: 0.554.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.276. Acc: 0.895. Test loss: 0.040.Test acc: 0.944\n",
      "Epoch [2/10]. Loss: 0.173. Acc: 0.947. Test loss: 0.023.Test acc: 0.949\n",
      "Epoch [3/10]. Loss: 0.139. Acc: 0.954. Test loss: 0.136.Test acc: 0.929\n",
      "Epoch [4/10]. Loss: 0.088. Acc: 0.962. Test loss: 0.008.Test acc: 0.935\n",
      "Epoch [5/10]. Loss: 0.084. Acc: 0.968. Test loss: 0.403.Test acc: 0.939\n",
      "Epoch [6/10]. Loss: 0.052. Acc: 0.973. Test loss: 0.000.Test acc: 0.943\n",
      "Epoch [7/10]. Loss: 0.064. Acc: 0.981. Test loss: 0.001.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.044. Acc: 0.984. Test loss: 0.032.Test acc: 0.944\n",
      "Epoch [9/10]. Loss: 0.034. Acc: 0.986. Test loss: 0.000.Test acc: 0.939\n",
      "Epoch [10/10]. Loss: 0.032. Acc: 0.989. Test loss: 0.082.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.181. Acc: 0.892. Test loss: 0.429.Test acc: 0.914\n",
      "Epoch [2/10]. Loss: 0.151. Acc: 0.947. Test loss: 0.004.Test acc: 0.944\n",
      "Epoch [3/10]. Loss: 0.126. Acc: 0.957. Test loss: 0.027.Test acc: 0.949\n",
      "Epoch [4/10]. Loss: 0.118. Acc: 0.964. Test loss: 0.009.Test acc: 0.933\n",
      "Epoch [5/10]. Loss: 0.108. Acc: 0.969. Test loss: 0.072.Test acc: 0.940\n",
      "Epoch [6/10]. Loss: 0.061. Acc: 0.976. Test loss: 0.930.Test acc: 0.936\n",
      "Epoch [7/10]. Loss: 0.055. Acc: 0.981. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [8/10]. Loss: 0.052. Acc: 0.982. Test loss: 0.000.Test acc: 0.938\n",
      "Epoch [9/10]. Loss: 0.052. Acc: 0.986. Test loss: 0.003.Test acc: 0.941\n",
      "Epoch [10/10]. Loss: 0.027. Acc: 0.990. Test loss: 0.001.Test acc: 0.939\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.162. Acc: 0.937. Test loss: 0.017.Test acc: 0.944\n",
      "Epoch [2/10]. Loss: 0.162. Acc: 0.953. Test loss: 0.261.Test acc: 0.951\n",
      "Epoch [3/10]. Loss: 0.110. Acc: 0.961. Test loss: 0.840.Test acc: 0.953\n",
      "Epoch [4/10]. Loss: 0.111. Acc: 0.968. Test loss: 0.054.Test acc: 0.953\n",
      "Epoch [5/10]. Loss: 0.083. Acc: 0.974. Test loss: 0.056.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.061. Acc: 0.979. Test loss: 0.001.Test acc: 0.950\n",
      "Epoch [7/10]. Loss: 0.035. Acc: 0.982. Test loss: 0.023.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.104. Acc: 0.984. Test loss: 0.004.Test acc: 0.943\n",
      "Epoch [9/10]. Loss: 0.053. Acc: 0.986. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [10/10]. Loss: 0.041. Acc: 0.989. Test loss: 0.000.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.160. Acc: 0.937. Test loss: 0.069.Test acc: 0.945\n",
      "Epoch [2/10]. Loss: 0.165. Acc: 0.952. Test loss: 0.005.Test acc: 0.948\n",
      "Epoch [3/10]. Loss: 0.148. Acc: 0.959. Test loss: 0.010.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.092. Acc: 0.967. Test loss: 0.053.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.131. Acc: 0.971. Test loss: 0.017.Test acc: 0.950\n",
      "Epoch [6/10]. Loss: 0.055. Acc: 0.976. Test loss: 0.011.Test acc: 0.948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]. Loss: 0.056. Acc: 0.980. Test loss: 1.464.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.047. Acc: 0.984. Test loss: 0.000.Test acc: 0.942\n",
      "Epoch [9/10]. Loss: 0.029. Acc: 0.987. Test loss: 0.005.Test acc: 0.941\n",
      "Epoch [10/10]. Loss: 0.022. Acc: 0.989. Test loss: 0.000.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.196. Acc: 0.918. Test loss: 0.020.Test acc: 0.937\n",
      "Epoch [2/10]. Loss: 0.177. Acc: 0.954. Test loss: 0.067.Test acc: 0.951\n",
      "Epoch [3/10]. Loss: 0.119. Acc: 0.960. Test loss: 0.030.Test acc: 0.951\n",
      "Epoch [4/10]. Loss: 0.105. Acc: 0.967. Test loss: 0.004.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.056. Acc: 0.972. Test loss: 0.026.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.046. Acc: 0.975. Test loss: 0.106.Test acc: 0.952\n",
      "Epoch [7/10]. Loss: 0.056. Acc: 0.980. Test loss: 0.006.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.034. Acc: 0.984. Test loss: 0.000.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.035. Acc: 0.987. Test loss: 0.002.Test acc: 0.941\n",
      "Epoch [10/10]. Loss: 0.035. Acc: 0.989. Test loss: 0.000.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.230. Acc: 0.890. Test loss: 0.157.Test acc: 0.936\n",
      "Epoch [2/10]. Loss: 0.157. Acc: 0.938. Test loss: 0.008.Test acc: 0.936\n",
      "Epoch [3/10]. Loss: 0.118. Acc: 0.953. Test loss: 0.012.Test acc: 0.942\n",
      "Epoch [4/10]. Loss: 0.103. Acc: 0.961. Test loss: 1.096.Test acc: 0.942\n",
      "Epoch [5/10]. Loss: 0.069. Acc: 0.968. Test loss: 0.001.Test acc: 0.940\n",
      "Epoch [6/10]. Loss: 0.114. Acc: 0.969. Test loss: 0.001.Test acc: 0.936\n",
      "Epoch [7/10]. Loss: 0.082. Acc: 0.975. Test loss: 0.005.Test acc: 0.928\n",
      "Epoch [8/10]. Loss: 0.095. Acc: 0.979. Test loss: 0.000.Test acc: 0.942\n",
      "Epoch [9/10]. Loss: 0.036. Acc: 0.983. Test loss: 0.040.Test acc: 0.940\n",
      "Epoch [10/10]. Loss: 0.062. Acc: 0.986. Test loss: 0.387.Test acc: 0.936\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.195. Acc: 0.889. Test loss: 0.132.Test acc: 0.931\n",
      "Epoch [2/10]. Loss: 0.205. Acc: 0.937. Test loss: 0.050.Test acc: 0.929\n",
      "Epoch [3/10]. Loss: 0.184. Acc: 0.943. Test loss: 0.457.Test acc: 0.935\n",
      "Epoch [4/10]. Loss: 0.091. Acc: 0.957. Test loss: 0.037.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.055. Acc: 0.966. Test loss: 1.062.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.055. Acc: 0.970. Test loss: 0.590.Test acc: 0.949\n",
      "Epoch [7/10]. Loss: 0.058. Acc: 0.975. Test loss: 0.043.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.041. Acc: 0.980. Test loss: 0.288.Test acc: 0.947\n",
      "Epoch [9/10]. Loss: 0.041. Acc: 0.980. Test loss: 0.430.Test acc: 0.939\n",
      "Epoch [10/10]. Loss: 0.041. Acc: 0.986. Test loss: 0.000.Test acc: 0.940\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.249. Acc: 0.859. Test loss: 0.219.Test acc: 0.886\n",
      "Epoch [2/10]. Loss: 0.193. Acc: 0.920. Test loss: 0.025.Test acc: 0.925\n",
      "Epoch [3/10]. Loss: 0.136. Acc: 0.934. Test loss: 0.017.Test acc: 0.934\n",
      "Epoch [4/10]. Loss: 0.086. Acc: 0.948. Test loss: 0.035.Test acc: 0.941\n",
      "Epoch [5/10]. Loss: 0.090. Acc: 0.955. Test loss: 0.017.Test acc: 0.945\n",
      "Epoch [6/10]. Loss: 0.121. Acc: 0.963. Test loss: 0.002.Test acc: 0.939\n",
      "Epoch [7/10]. Loss: 0.092. Acc: 0.966. Test loss: 0.172.Test acc: 0.940\n",
      "Epoch [8/10]. Loss: 0.077. Acc: 0.971. Test loss: 0.007.Test acc: 0.942\n",
      "Epoch [9/10]. Loss: 0.061. Acc: 0.972. Test loss: 0.440.Test acc: 0.940\n",
      "Epoch [10/10]. Loss: 0.043. Acc: 0.975. Test loss: 1.266.Test acc: 0.934\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.167. Acc: 0.930. Test loss: 0.042.Test acc: 0.931\n",
      "Epoch [2/10]. Loss: 0.139. Acc: 0.937. Test loss: 0.072.Test acc: 0.935\n",
      "Epoch [3/10]. Loss: 0.144. Acc: 0.949. Test loss: 0.004.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.104. Acc: 0.960. Test loss: 0.441.Test acc: 0.951\n",
      "Epoch [5/10]. Loss: 0.132. Acc: 0.968. Test loss: 0.031.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.060. Acc: 0.973. Test loss: 0.013.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.048. Acc: 0.977. Test loss: 0.005.Test acc: 0.952\n",
      "Epoch [8/10]. Loss: 0.061. Acc: 0.979. Test loss: 0.037.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.055. Acc: 0.983. Test loss: 0.023.Test acc: 0.951\n",
      "Epoch [10/10]. Loss: 0.042. Acc: 0.986. Test loss: 0.015.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.290. Acc: 0.928. Test loss: 0.025.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.162. Acc: 0.941. Test loss: 0.719.Test acc: 0.946\n",
      "Epoch [3/10]. Loss: 0.135. Acc: 0.954. Test loss: 0.886.Test acc: 0.951\n",
      "Epoch [4/10]. Loss: 0.084. Acc: 0.963. Test loss: 0.018.Test acc: 0.952\n",
      "Epoch [5/10]. Loss: 0.097. Acc: 0.970. Test loss: 0.002.Test acc: 0.950\n",
      "Epoch [6/10]. Loss: 0.081. Acc: 0.975. Test loss: 0.088.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.073. Acc: 0.979. Test loss: 0.219.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.033. Acc: 0.982. Test loss: 0.028.Test acc: 0.948\n",
      "Epoch [9/10]. Loss: 0.036. Acc: 0.986. Test loss: 0.207.Test acc: 0.949\n",
      "Epoch [10/10]. Loss: 0.035. Acc: 0.986. Test loss: 0.012.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.190. Acc: 0.913. Test loss: 0.034.Test acc: 0.929\n",
      "Epoch [2/10]. Loss: 0.155. Acc: 0.941. Test loss: 0.062.Test acc: 0.948\n",
      "Epoch [3/10]. Loss: 0.151. Acc: 0.954. Test loss: 0.015.Test acc: 0.948\n",
      "Epoch [4/10]. Loss: 0.110. Acc: 0.961. Test loss: 0.099.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.151. Acc: 0.967. Test loss: 0.006.Test acc: 0.951\n",
      "Epoch [6/10]. Loss: 0.118. Acc: 0.971. Test loss: 0.247.Test acc: 0.950\n",
      "Epoch [7/10]. Loss: 0.071. Acc: 0.974. Test loss: 0.002.Test acc: 0.950\n",
      "Epoch [8/10]. Loss: 0.075. Acc: 0.974. Test loss: 0.004.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.045. Acc: 0.979. Test loss: 0.182.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.100. Acc: 0.983. Test loss: 1.249.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.157. Acc: 0.891. Test loss: 0.035.Test acc: 0.937\n",
      "Epoch [2/10]. Loss: 0.120. Acc: 0.948. Test loss: 0.047.Test acc: 0.943\n",
      "Epoch [3/10]. Loss: 0.121. Acc: 0.961. Test loss: 0.034.Test acc: 0.944\n",
      "Epoch [4/10]. Loss: 0.094. Acc: 0.965. Test loss: 0.477.Test acc: 0.941\n",
      "Epoch [5/10]. Loss: 0.089. Acc: 0.973. Test loss: 0.121.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.053. Acc: 0.980. Test loss: 0.000.Test acc: 0.949\n",
      "Epoch [7/10]. Loss: 0.056. Acc: 0.984. Test loss: 0.011.Test acc: 0.941\n",
      "Epoch [8/10]. Loss: 0.031. Acc: 0.987. Test loss: 0.583.Test acc: 0.942\n",
      "Epoch [9/10]. Loss: 0.039. Acc: 0.990. Test loss: 0.001.Test acc: 0.942\n",
      "Epoch [10/10]. Loss: 0.026. Acc: 0.992. Test loss: 0.267.Test acc: 0.942\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.181. Acc: 0.896. Test loss: 0.051.Test acc: 0.941\n",
      "Epoch [2/10]. Loss: 0.129. Acc: 0.949. Test loss: 0.018.Test acc: 0.949\n",
      "Epoch [3/10]. Loss: 0.129. Acc: 0.958. Test loss: 1.022.Test acc: 0.948\n",
      "Epoch [4/10]. Loss: 0.055. Acc: 0.965. Test loss: 0.908.Test acc: 0.946\n",
      "Epoch [5/10]. Loss: 0.062. Acc: 0.976. Test loss: 0.037.Test acc: 0.941\n",
      "Epoch [6/10]. Loss: 0.080. Acc: 0.982. Test loss: 1.584.Test acc: 0.948\n",
      "Epoch [7/10]. Loss: 0.051. Acc: 0.984. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.051. Acc: 0.987. Test loss: 0.012.Test acc: 0.943\n",
      "Epoch [9/10]. Loss: 0.040. Acc: 0.990. Test loss: 0.001.Test acc: 0.936\n",
      "Epoch [10/10]. Loss: 0.018. Acc: 0.990. Test loss: 0.054.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.172. Acc: 0.880. Test loss: 0.147.Test acc: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]. Loss: 0.137. Acc: 0.937. Test loss: 0.015.Test acc: 0.941\n",
      "Epoch [3/10]. Loss: 0.157. Acc: 0.951. Test loss: 0.012.Test acc: 0.935\n",
      "Epoch [4/10]. Loss: 0.108. Acc: 0.958. Test loss: 0.008.Test acc: 0.946\n",
      "Epoch [5/10]. Loss: 0.072. Acc: 0.965. Test loss: 0.007.Test acc: 0.944\n",
      "Epoch [6/10]. Loss: 0.072. Acc: 0.971. Test loss: 0.046.Test acc: 0.943\n",
      "Epoch [7/10]. Loss: 0.080. Acc: 0.975. Test loss: 0.031.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.034. Acc: 0.980. Test loss: 1.839.Test acc: 0.943\n",
      "Epoch [9/10]. Loss: 0.045. Acc: 0.982. Test loss: 0.352.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.022. Acc: 0.988. Test loss: 1.318.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.129. Acc: 0.941. Test loss: 0.046.Test acc: 0.949\n",
      "Epoch [2/10]. Loss: 0.095. Acc: 0.956. Test loss: 0.005.Test acc: 0.950\n",
      "Epoch [3/10]. Loss: 0.125. Acc: 0.963. Test loss: 0.087.Test acc: 0.951\n",
      "Epoch [4/10]. Loss: 0.077. Acc: 0.973. Test loss: 0.006.Test acc: 0.947\n",
      "Epoch [5/10]. Loss: 0.059. Acc: 0.977. Test loss: 0.018.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.030. Acc: 0.983. Test loss: 0.000.Test acc: 0.948\n",
      "Epoch [7/10]. Loss: 0.045. Acc: 0.989. Test loss: 0.774.Test acc: 0.949\n",
      "Epoch [8/10]. Loss: 0.030. Acc: 0.985. Test loss: 2.360.Test acc: 0.948\n",
      "Epoch [9/10]. Loss: 0.044. Acc: 0.989. Test loss: 0.024.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.039. Acc: 0.991. Test loss: 0.064.Test acc: 0.946\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.186. Acc: 0.932. Test loss: 0.042.Test acc: 0.934\n",
      "Epoch [2/10]. Loss: 0.133. Acc: 0.942. Test loss: 0.023.Test acc: 0.948\n",
      "Epoch [3/10]. Loss: 0.095. Acc: 0.955. Test loss: 0.080.Test acc: 0.947\n",
      "Epoch [4/10]. Loss: 0.095. Acc: 0.962. Test loss: 0.018.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.080. Acc: 0.968. Test loss: 0.001.Test acc: 0.951\n",
      "Epoch [6/10]. Loss: 0.067. Acc: 0.974. Test loss: 0.012.Test acc: 0.945\n",
      "Epoch [7/10]. Loss: 0.070. Acc: 0.978. Test loss: 0.002.Test acc: 0.941\n",
      "Epoch [8/10]. Loss: 0.046. Acc: 0.979. Test loss: 0.042.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.036. Acc: 0.983. Test loss: 0.051.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.064. Acc: 0.986. Test loss: 0.260.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.163. Acc: 0.913. Test loss: 0.031.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.132. Acc: 0.942. Test loss: 0.858.Test acc: 0.947\n",
      "Epoch [3/10]. Loss: 0.112. Acc: 0.954. Test loss: 0.030.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.143. Acc: 0.963. Test loss: 0.130.Test acc: 0.951\n",
      "Epoch [5/10]. Loss: 0.080. Acc: 0.969. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [6/10]. Loss: 0.088. Acc: 0.976. Test loss: 0.001.Test acc: 0.948\n",
      "Epoch [7/10]. Loss: 0.053. Acc: 0.982. Test loss: 0.288.Test acc: 0.949\n",
      "Epoch [8/10]. Loss: 0.035. Acc: 0.985. Test loss: 0.275.Test acc: 0.952\n",
      "Epoch [9/10]. Loss: 0.037. Acc: 0.987. Test loss: 0.002.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.029. Acc: 0.988. Test loss: 0.012.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.201. Acc: 0.578. Test loss: 0.051.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.199. Acc: 0.936. Test loss: 0.033.Test acc: 0.937\n",
      "Epoch [3/10]. Loss: 0.146. Acc: 0.941. Test loss: 0.624.Test acc: 0.938\n",
      "Epoch [4/10]. Loss: 0.125. Acc: 0.950. Test loss: 0.019.Test acc: 0.941\n",
      "Epoch [5/10]. Loss: 0.140. Acc: 0.958. Test loss: 0.024.Test acc: 0.946\n",
      "Epoch [6/10]. Loss: 0.160. Acc: 0.964. Test loss: 0.104.Test acc: 0.941\n",
      "Epoch [7/10]. Loss: 0.063. Acc: 0.967. Test loss: 0.016.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.089. Acc: 0.972. Test loss: 0.008.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.060. Acc: 0.976. Test loss: 0.027.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.073. Acc: 0.978. Test loss: 0.019.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.249. Acc: 0.565. Test loss: 0.039.Test acc: 0.932\n",
      "Epoch [2/10]. Loss: 0.218. Acc: 0.937. Test loss: 0.117.Test acc: 0.932\n",
      "Epoch [3/10]. Loss: 0.170. Acc: 0.944. Test loss: 0.159.Test acc: 0.936\n",
      "Epoch [4/10]. Loss: 0.149. Acc: 0.951. Test loss: 0.045.Test acc: 0.942\n",
      "Epoch [5/10]. Loss: 0.104. Acc: 0.956. Test loss: 0.013.Test acc: 0.946\n",
      "Epoch [6/10]. Loss: 0.185. Acc: 0.962. Test loss: 0.286.Test acc: 0.948\n",
      "Epoch [7/10]. Loss: 0.156. Acc: 0.964. Test loss: 0.025.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.129. Acc: 0.969. Test loss: 0.014.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.079. Acc: 0.973. Test loss: 1.110.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.086. Acc: 0.977. Test loss: 0.031.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.226. Acc: 0.542. Test loss: 0.599.Test acc: 0.932\n",
      "Epoch [2/10]. Loss: 0.211. Acc: 0.936. Test loss: 0.042.Test acc: 0.937\n",
      "Epoch [3/10]. Loss: 0.159. Acc: 0.939. Test loss: 0.024.Test acc: 0.937\n",
      "Epoch [4/10]. Loss: 0.133. Acc: 0.948. Test loss: 0.014.Test acc: 0.943\n",
      "Epoch [5/10]. Loss: 0.117. Acc: 0.955. Test loss: 0.029.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.163. Acc: 0.961. Test loss: 0.076.Test acc: 0.947\n",
      "Epoch [7/10]. Loss: 0.110. Acc: 0.965. Test loss: 0.010.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.080. Acc: 0.968. Test loss: 0.200.Test acc: 0.939\n",
      "Epoch [9/10]. Loss: 0.111. Acc: 0.974. Test loss: 0.004.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.054. Acc: 0.976. Test loss: 0.009.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.218. Acc: 0.930. Test loss: 0.048.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.206. Acc: 0.936. Test loss: 0.037.Test acc: 0.941\n",
      "Epoch [3/10]. Loss: 0.134. Acc: 0.947. Test loss: 0.185.Test acc: 0.946\n",
      "Epoch [4/10]. Loss: 0.131. Acc: 0.953. Test loss: 0.031.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.090. Acc: 0.958. Test loss: 0.339.Test acc: 0.949\n",
      "Epoch [6/10]. Loss: 0.139. Acc: 0.963. Test loss: 0.012.Test acc: 0.952\n",
      "Epoch [7/10]. Loss: 0.127. Acc: 0.968. Test loss: 0.009.Test acc: 0.952\n",
      "Epoch [8/10]. Loss: 0.058. Acc: 0.973. Test loss: 0.009.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.083. Acc: 0.977. Test loss: 0.005.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.052. Acc: 0.979. Test loss: 0.025.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.233. Acc: 0.930. Test loss: 0.510.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.221. Acc: 0.935. Test loss: 0.032.Test acc: 0.943\n",
      "Epoch [3/10]. Loss: 0.149. Acc: 0.948. Test loss: 0.144.Test acc: 0.945\n",
      "Epoch [4/10]. Loss: 0.159. Acc: 0.955. Test loss: 0.025.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.121. Acc: 0.959. Test loss: 0.030.Test acc: 0.951\n",
      "Epoch [6/10]. Loss: 0.118. Acc: 0.964. Test loss: 0.008.Test acc: 0.950\n",
      "Epoch [7/10]. Loss: 0.111. Acc: 0.969. Test loss: 0.006.Test acc: 0.952\n",
      "Epoch [8/10]. Loss: 0.067. Acc: 0.973. Test loss: 0.030.Test acc: 0.951\n",
      "Epoch [9/10]. Loss: 0.088. Acc: 0.978. Test loss: 0.006.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.070. Acc: 0.981. Test loss: 0.092.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.273. Acc: 0.930. Test loss: 0.041.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.216. Acc: 0.934. Test loss: 0.040.Test acc: 0.938\n",
      "Epoch [3/10]. Loss: 0.217. Acc: 0.946. Test loss: 0.781.Test acc: 0.946\n",
      "Epoch [4/10]. Loss: 0.143. Acc: 0.953. Test loss: 0.069.Test acc: 0.948\n",
      "Epoch [5/10]. Loss: 0.080. Acc: 0.959. Test loss: 0.063.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.111. Acc: 0.964. Test loss: 0.011.Test acc: 0.952\n",
      "Epoch [7/10]. Loss: 0.100. Acc: 0.968. Test loss: 0.041.Test acc: 0.951\n",
      "Epoch [8/10]. Loss: 0.109. Acc: 0.972. Test loss: 0.018.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.072. Acc: 0.975. Test loss: 0.018.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.042. Acc: 0.979. Test loss: 0.002.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.210. Acc: 0.641. Test loss: 0.072.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.179. Acc: 0.939. Test loss: 0.539.Test acc: 0.938\n",
      "Epoch [3/10]. Loss: 0.101. Acc: 0.945. Test loss: 0.067.Test acc: 0.945\n",
      "Epoch [4/10]. Loss: 0.106. Acc: 0.953. Test loss: 0.118.Test acc: 0.943\n",
      "Epoch [5/10]. Loss: 0.071. Acc: 0.959. Test loss: 0.013.Test acc: 0.950\n",
      "Epoch [6/10]. Loss: 0.147. Acc: 0.963. Test loss: 0.173.Test acc: 0.947\n",
      "Epoch [7/10]. Loss: 0.115. Acc: 0.968. Test loss: 0.003.Test acc: 0.941\n",
      "Epoch [8/10]. Loss: 0.087. Acc: 0.973. Test loss: 0.017.Test acc: 0.943\n",
      "Epoch [9/10]. Loss: 0.050. Acc: 0.976. Test loss: 0.010.Test acc: 0.951\n",
      "Epoch [10/10]. Loss: 0.058. Acc: 0.982. Test loss: 0.002.Test acc: 0.941\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.224. Acc: 0.687. Test loss: 0.084.Test acc: 0.934\n",
      "Epoch [2/10]. Loss: 0.185. Acc: 0.938. Test loss: 0.069.Test acc: 0.939\n",
      "Epoch [3/10]. Loss: 0.144. Acc: 0.945. Test loss: 0.826.Test acc: 0.942\n",
      "Epoch [4/10]. Loss: 0.123. Acc: 0.952. Test loss: 0.109.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.116. Acc: 0.957. Test loss: 0.019.Test acc: 0.949\n",
      "Epoch [6/10]. Loss: 0.076. Acc: 0.965. Test loss: 0.084.Test acc: 0.950\n",
      "Epoch [7/10]. Loss: 0.100. Acc: 0.968. Test loss: 0.629.Test acc: 0.939\n",
      "Epoch [8/10]. Loss: 0.098. Acc: 0.972. Test loss: 0.001.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.061. Acc: 0.978. Test loss: 0.014.Test acc: 0.946\n",
      "Epoch [10/10]. Loss: 0.032. Acc: 0.982. Test loss: 0.411.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.227. Acc: 0.631. Test loss: 0.072.Test acc: 0.934\n",
      "Epoch [2/10]. Loss: 0.169. Acc: 0.938. Test loss: 0.024.Test acc: 0.940\n",
      "Epoch [3/10]. Loss: 0.167. Acc: 0.946. Test loss: 0.028.Test acc: 0.943\n",
      "Epoch [4/10]. Loss: 0.114. Acc: 0.954. Test loss: 0.092.Test acc: 0.943\n",
      "Epoch [5/10]. Loss: 0.155. Acc: 0.958. Test loss: 0.022.Test acc: 0.944\n",
      "Epoch [6/10]. Loss: 0.118. Acc: 0.963. Test loss: 0.028.Test acc: 0.947\n",
      "Epoch [7/10]. Loss: 0.082. Acc: 0.968. Test loss: 0.012.Test acc: 0.946\n",
      "Epoch [8/10]. Loss: 0.081. Acc: 0.974. Test loss: 0.018.Test acc: 0.947\n",
      "Epoch [9/10]. Loss: 0.076. Acc: 0.977. Test loss: 0.016.Test acc: 0.941\n",
      "Epoch [10/10]. Loss: 0.095. Acc: 0.980. Test loss: 0.073.Test acc: 0.945\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.201. Acc: 0.906. Test loss: 0.071.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.127. Acc: 0.941. Test loss: 0.025.Test acc: 0.943\n",
      "Epoch [3/10]. Loss: 0.142. Acc: 0.949. Test loss: 0.018.Test acc: 0.947\n",
      "Epoch [4/10]. Loss: 0.134. Acc: 0.956. Test loss: 0.030.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.101. Acc: 0.961. Test loss: 0.688.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.148. Acc: 0.965. Test loss: 0.004.Test acc: 0.952\n",
      "Epoch [7/10]. Loss: 0.114. Acc: 0.969. Test loss: 0.037.Test acc: 0.952\n",
      "Epoch [8/10]. Loss: 0.105. Acc: 0.975. Test loss: 0.018.Test acc: 0.948\n",
      "Epoch [9/10]. Loss: 0.085. Acc: 0.977. Test loss: 0.463.Test acc: 0.949\n",
      "Epoch [10/10]. Loss: 0.066. Acc: 0.981. Test loss: 0.001.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.244. Acc: 0.928. Test loss: 0.073.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.197. Acc: 0.940. Test loss: 0.038.Test acc: 0.944\n",
      "Epoch [3/10]. Loss: 0.133. Acc: 0.950. Test loss: 0.100.Test acc: 0.948\n",
      "Epoch [4/10]. Loss: 0.134. Acc: 0.956. Test loss: 0.014.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.134. Acc: 0.960. Test loss: 0.018.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.097. Acc: 0.965. Test loss: 0.380.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.078. Acc: 0.969. Test loss: 0.027.Test acc: 0.950\n",
      "Epoch [8/10]. Loss: 0.085. Acc: 0.975. Test loss: 0.049.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.048. Acc: 0.979. Test loss: 0.021.Test acc: 0.953\n",
      "Epoch [10/10]. Loss: 0.061. Acc: 0.982. Test loss: 0.789.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.176. Acc: 0.890. Test loss: 0.063.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.154. Acc: 0.941. Test loss: 0.027.Test acc: 0.945\n",
      "Epoch [3/10]. Loss: 0.133. Acc: 0.949. Test loss: 0.035.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.146. Acc: 0.955. Test loss: 0.033.Test acc: 0.952\n",
      "Epoch [5/10]. Loss: 0.117. Acc: 0.960. Test loss: 0.012.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.126. Acc: 0.965. Test loss: 1.216.Test acc: 0.953\n",
      "Epoch [7/10]. Loss: 0.101. Acc: 0.969. Test loss: 0.017.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.056. Acc: 0.974. Test loss: 0.012.Test acc: 0.946\n",
      "Epoch [9/10]. Loss: 0.075. Acc: 0.977. Test loss: 0.035.Test acc: 0.949\n",
      "Epoch [10/10]. Loss: 0.062. Acc: 0.981. Test loss: 0.029.Test acc: 0.951\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.224. Acc: 0.608. Test loss: 0.049.Test acc: 0.935\n",
      "Epoch [2/10]. Loss: 0.163. Acc: 0.941. Test loss: 0.033.Test acc: 0.937\n",
      "Epoch [3/10]. Loss: 0.180. Acc: 0.949. Test loss: 0.028.Test acc: 0.942\n",
      "Epoch [4/10]. Loss: 0.127. Acc: 0.959. Test loss: 0.925.Test acc: 0.943\n",
      "Epoch [5/10]. Loss: 0.085. Acc: 0.966. Test loss: 0.028.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.077. Acc: 0.971. Test loss: 0.014.Test acc: 0.942\n",
      "Epoch [7/10]. Loss: 0.070. Acc: 0.976. Test loss: 0.486.Test acc: 0.949\n",
      "Epoch [8/10]. Loss: 0.063. Acc: 0.979. Test loss: 0.633.Test acc: 0.944\n",
      "Epoch [9/10]. Loss: 0.066. Acc: 0.982. Test loss: 0.011.Test acc: 0.947\n",
      "Epoch [10/10]. Loss: 0.056. Acc: 0.986. Test loss: 0.826.Test acc: 0.949\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.310. Acc: 0.580. Test loss: 0.428.Test acc: 0.934\n",
      "Epoch [2/10]. Loss: 0.212. Acc: 0.941. Test loss: 0.074.Test acc: 0.934\n",
      "Epoch [3/10]. Loss: 0.137. Acc: 0.945. Test loss: 0.052.Test acc: 0.942\n",
      "Epoch [4/10]. Loss: 0.123. Acc: 0.956. Test loss: 0.115.Test acc: 0.945\n",
      "Epoch [5/10]. Loss: 0.144. Acc: 0.962. Test loss: 0.019.Test acc: 0.942\n",
      "Epoch [6/10]. Loss: 0.109. Acc: 0.969. Test loss: 0.027.Test acc: 0.941\n",
      "Epoch [7/10]. Loss: 0.056. Acc: 0.973. Test loss: 1.155.Test acc: 0.945\n",
      "Epoch [8/10]. Loss: 0.098. Acc: 0.978. Test loss: 0.014.Test acc: 0.942\n",
      "Epoch [9/10]. Loss: 0.077. Acc: 0.981. Test loss: 0.026.Test acc: 0.940\n",
      "Epoch [10/10]. Loss: 0.064. Acc: 0.984. Test loss: 0.003.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.323. Acc: 0.592. Test loss: 0.037.Test acc: 0.932\n",
      "Epoch [2/10]. Loss: 0.144. Acc: 0.940. Test loss: 0.023.Test acc: 0.939\n",
      "Epoch [3/10]. Loss: 0.178. Acc: 0.946. Test loss: 0.029.Test acc: 0.943\n",
      "Epoch [4/10]. Loss: 0.114. Acc: 0.956. Test loss: 0.090.Test acc: 0.946\n",
      "Epoch [5/10]. Loss: 0.136. Acc: 0.963. Test loss: 0.010.Test acc: 0.948\n",
      "Epoch [6/10]. Loss: 0.093. Acc: 0.968. Test loss: 0.042.Test acc: 0.939\n",
      "Epoch [7/10]. Loss: 0.102. Acc: 0.972. Test loss: 0.016.Test acc: 0.938\n",
      "Epoch [8/10]. Loss: 0.101. Acc: 0.977. Test loss: 0.030.Test acc: 0.945\n",
      "Epoch [9/10]. Loss: 0.083. Acc: 0.981. Test loss: 0.007.Test acc: 0.946\n",
      "Epoch [10/10]. Loss: 0.079. Acc: 0.984. Test loss: 0.584.Test acc: 0.944\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.221. Acc: 0.929. Test loss: 0.037.Test acc: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]. Loss: 0.152. Acc: 0.939. Test loss: 0.037.Test acc: 0.942\n",
      "Epoch [3/10]. Loss: 0.192. Acc: 0.952. Test loss: 0.019.Test acc: 0.948\n",
      "Epoch [4/10]. Loss: 0.107. Acc: 0.960. Test loss: 0.070.Test acc: 0.951\n",
      "Epoch [5/10]. Loss: 0.101. Acc: 0.966. Test loss: 0.209.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.111. Acc: 0.971. Test loss: 0.039.Test acc: 0.949\n",
      "Epoch [7/10]. Loss: 0.066. Acc: 0.976. Test loss: 0.059.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.064. Acc: 0.981. Test loss: 0.012.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.073. Acc: 0.983. Test loss: 0.094.Test acc: 0.950\n",
      "Epoch [10/10]. Loss: 0.077. Acc: 0.987. Test loss: 0.010.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.156. Acc: 0.930. Test loss: 0.050.Test acc: 0.933\n",
      "Epoch [2/10]. Loss: 0.157. Acc: 0.940. Test loss: 0.112.Test acc: 0.945\n",
      "Epoch [3/10]. Loss: 0.121. Acc: 0.952. Test loss: 0.270.Test acc: 0.947\n",
      "Epoch [4/10]. Loss: 0.112. Acc: 0.958. Test loss: 1.032.Test acc: 0.949\n",
      "Epoch [5/10]. Loss: 0.129. Acc: 0.965. Test loss: 0.210.Test acc: 0.946\n",
      "Epoch [6/10]. Loss: 0.083. Acc: 0.971. Test loss: 0.004.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.071. Acc: 0.976. Test loss: 0.004.Test acc: 0.949\n",
      "Epoch [8/10]. Loss: 0.033. Acc: 0.980. Test loss: 0.823.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.045. Acc: 0.984. Test loss: 0.023.Test acc: 0.950\n",
      "Epoch [10/10]. Loss: 0.097. Acc: 0.986. Test loss: 0.042.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.211. Acc: 0.930. Test loss: 0.665.Test acc: 0.930\n",
      "Epoch [2/10]. Loss: 0.198. Acc: 0.937. Test loss: 0.025.Test acc: 0.943\n",
      "Epoch [3/10]. Loss: 0.148. Acc: 0.952. Test loss: 0.017.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.168. Acc: 0.959. Test loss: 0.975.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.095. Acc: 0.965. Test loss: 0.086.Test acc: 0.950\n",
      "Epoch [6/10]. Loss: 0.056. Acc: 0.970. Test loss: 0.012.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.071. Acc: 0.974. Test loss: 0.003.Test acc: 0.951\n",
      "Epoch [8/10]. Loss: 0.081. Acc: 0.979. Test loss: 0.010.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.055. Acc: 0.983. Test loss: 0.017.Test acc: 0.951\n",
      "Epoch [10/10]. Loss: 0.052. Acc: 0.986. Test loss: 0.004.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.177. Acc: 0.671. Test loss: 0.078.Test acc: 0.940\n",
      "Epoch [2/10]. Loss: 0.156. Acc: 0.943. Test loss: 0.026.Test acc: 0.939\n",
      "Epoch [3/10]. Loss: 0.109. Acc: 0.952. Test loss: 0.030.Test acc: 0.944\n",
      "Epoch [4/10]. Loss: 0.115. Acc: 0.960. Test loss: 0.061.Test acc: 0.943\n",
      "Epoch [5/10]. Loss: 0.170. Acc: 0.965. Test loss: 0.016.Test acc: 0.946\n",
      "Epoch [6/10]. Loss: 0.131. Acc: 0.971. Test loss: 0.017.Test acc: 0.948\n",
      "Epoch [7/10]. Loss: 0.063. Acc: 0.975. Test loss: 0.034.Test acc: 0.946\n",
      "Epoch [8/10]. Loss: 0.021. Acc: 0.981. Test loss: 0.008.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.059. Acc: 0.983. Test loss: 0.022.Test acc: 0.948\n",
      "Epoch [10/10]. Loss: 0.051. Acc: 0.984. Test loss: 0.128.Test acc: 0.943\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.252. Acc: 0.708. Test loss: 0.612.Test acc: 0.940\n",
      "Epoch [2/10]. Loss: 0.178. Acc: 0.942. Test loss: 0.222.Test acc: 0.941\n",
      "Epoch [3/10]. Loss: 0.088. Acc: 0.954. Test loss: 1.360.Test acc: 0.945\n",
      "Epoch [4/10]. Loss: 0.130. Acc: 0.959. Test loss: 0.732.Test acc: 0.946\n",
      "Epoch [5/10]. Loss: 0.169. Acc: 0.967. Test loss: 0.013.Test acc: 0.945\n",
      "Epoch [6/10]. Loss: 0.076. Acc: 0.971. Test loss: 0.014.Test acc: 0.945\n",
      "Epoch [7/10]. Loss: 0.067. Acc: 0.977. Test loss: 0.100.Test acc: 0.946\n",
      "Epoch [8/10]. Loss: 0.033. Acc: 0.981. Test loss: 0.001.Test acc: 0.948\n",
      "Epoch [9/10]. Loss: 0.059. Acc: 0.984. Test loss: 0.458.Test acc: 0.939\n",
      "Epoch [10/10]. Loss: 0.025. Acc: 0.988. Test loss: 0.054.Test acc: 0.947\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.184. Acc: 0.665. Test loss: 0.057.Test acc: 0.942\n",
      "Epoch [2/10]. Loss: 0.195. Acc: 0.941. Test loss: 0.127.Test acc: 0.945\n",
      "Epoch [3/10]. Loss: 0.174. Acc: 0.952. Test loss: 0.820.Test acc: 0.947\n",
      "Epoch [4/10]. Loss: 0.149. Acc: 0.959. Test loss: 0.028.Test acc: 0.948\n",
      "Epoch [5/10]. Loss: 0.085. Acc: 0.966. Test loss: 0.096.Test acc: 0.947\n",
      "Epoch [6/10]. Loss: 0.083. Acc: 0.972. Test loss: 0.037.Test acc: 0.945\n",
      "Epoch [7/10]. Loss: 0.076. Acc: 0.977. Test loss: 0.978.Test acc: 0.947\n",
      "Epoch [8/10]. Loss: 0.108. Acc: 0.982. Test loss: 0.548.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.044. Acc: 0.984. Test loss: 0.008.Test acc: 0.945\n",
      "Epoch [10/10]. Loss: 0.047. Acc: 0.986. Test loss: 0.001.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
      "Epoch [1/10]. Loss: 0.196. Acc: 0.915. Test loss: 0.059.Test acc: 0.935\n",
      "Epoch [2/10]. Loss: 0.207. Acc: 0.943. Test loss: 0.085.Test acc: 0.946\n",
      "Epoch [3/10]. Loss: 0.139. Acc: 0.955. Test loss: 0.033.Test acc: 0.950\n",
      "Epoch [4/10]. Loss: 0.119. Acc: 0.960. Test loss: 0.119.Test acc: 0.951\n",
      "Epoch [5/10]. Loss: 0.103. Acc: 0.967. Test loss: 0.018.Test acc: 0.951\n",
      "Epoch [6/10]. Loss: 0.090. Acc: 0.973. Test loss: 0.527.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.116. Acc: 0.977. Test loss: 0.003.Test acc: 0.950\n",
      "Epoch [8/10]. Loss: 0.070. Acc: 0.982. Test loss: 0.479.Test acc: 0.951\n",
      "Epoch [9/10]. Loss: 0.054. Acc: 0.984. Test loss: 0.008.Test acc: 0.951\n",
      "Epoch [10/10]. Loss: 0.063. Acc: 0.987. Test loss: 0.020.Test acc: 0.950\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
      "Epoch [1/10]. Loss: 0.217. Acc: 0.872. Test loss: 0.573.Test acc: 0.935\n",
      "Epoch [2/10]. Loss: 0.170. Acc: 0.944. Test loss: 0.626.Test acc: 0.946\n",
      "Epoch [3/10]. Loss: 0.138. Acc: 0.954. Test loss: 0.020.Test acc: 0.949\n",
      "Epoch [4/10]. Loss: 0.138. Acc: 0.963. Test loss: 0.021.Test acc: 0.950\n",
      "Epoch [5/10]. Loss: 0.095. Acc: 0.968. Test loss: 0.142.Test acc: 0.952\n",
      "Epoch [6/10]. Loss: 0.084. Acc: 0.973. Test loss: 0.014.Test acc: 0.952\n",
      "Epoch [7/10]. Loss: 0.046. Acc: 0.978. Test loss: 0.006.Test acc: 0.950\n",
      "Epoch [8/10]. Loss: 0.066. Acc: 0.981. Test loss: 0.003.Test acc: 0.949\n",
      "Epoch [9/10]. Loss: 0.035. Acc: 0.984. Test loss: 0.075.Test acc: 0.944\n",
      "Epoch [10/10]. Loss: 0.065. Acc: 0.986. Test loss: 0.007.Test acc: 0.948\n",
      "Finished!\n",
      "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
      "Epoch [1/10]. Loss: 0.185. Acc: 0.914. Test loss: 0.100.Test acc: 0.940\n",
      "Epoch [2/10]. Loss: 0.154. Acc: 0.944. Test loss: 0.022.Test acc: 0.948\n",
      "Epoch [3/10]. Loss: 0.129. Acc: 0.955. Test loss: 0.018.Test acc: 0.952\n",
      "Epoch [4/10]. Loss: 0.137. Acc: 0.962. Test loss: 0.020.Test acc: 0.952\n",
      "Epoch [5/10]. Loss: 0.083. Acc: 0.967. Test loss: 0.014.Test acc: 0.946\n",
      "Epoch [6/10]. Loss: 0.094. Acc: 0.973. Test loss: 0.004.Test acc: 0.951\n",
      "Epoch [7/10]. Loss: 0.093. Acc: 0.978. Test loss: 0.021.Test acc: 0.948\n",
      "Epoch [8/10]. Loss: 0.060. Acc: 0.981. Test loss: 0.002.Test acc: 0.950\n",
      "Epoch [9/10]. Loss: 0.043. Acc: 0.984. Test loss: 0.002.Test acc: 0.947\n",
      "Epoch [10/10]. Loss: 0.051. Acc: 0.986. Test loss: 0.921.Test acc: 0.950\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "for epochs in n_epochs:\n",
    "    for lr in learning_rates:\n",
    "        for embedding_dim in e_dims:\n",
    "            for hidden_dim in h_dims:\n",
    "                for th in ths:\n",
    "                    for dp in dps:\n",
    "                        \n",
    "                        print(f'Hyper params: epochs - {epochs}, learning_rate - {lr}, '\n",
    "                             f'embedding_dim - {embedding_dim}, hidden_dim - {hidden_dim}, '\n",
    "                             f'threshold_level - {th}, drop_prob - {dp}.')\n",
    "                        model = LSTMFixedLen(vocab_size=max_words, \n",
    "                                             embedding_dim=embedding_dim, hidden_dim=hidden_dim, \n",
    "                                             drop_prob=dp, use_last=False)\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                        model = model.to(device)\n",
    "                        model.train()\n",
    "                        th = th\n",
    "\n",
    "                        train_loss_history = []\n",
    "                        test_loss_history = []\n",
    "\n",
    "\n",
    "                        for epoch in range(epochs):  \n",
    "                            running_items, running_right = 0.0, 0.0\n",
    "                            for i, data in enumerate(train_loader, 0):\n",
    "                                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                                # обнуляем градиент\n",
    "                                optimizer.zero_grad()\n",
    "                                outputs = model(inputs)\n",
    "\n",
    "                                loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "                                # подсчет ошибки на обучении\n",
    "                                loss = loss.item()\n",
    "                                running_items += len(labels)\n",
    "                                # подсчет метрики на обучении\n",
    "                                pred_labels = torch.squeeze((outputs > th).int())\n",
    "                                running_right += (labels == pred_labels).sum()\n",
    "\n",
    "                            # выводим статистику о процессе обучения\n",
    "                            model.eval()\n",
    "\n",
    "                            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "                                    #f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                                    f'Loss: {loss:.3f}. ' \\\n",
    "                                    f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "                            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "                            train_loss_history.append(loss)\n",
    "\n",
    "                                # выводим статистику на тестовых данных\n",
    "                            test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "                            for j, data in enumerate(val_loader):\n",
    "                                test_labels = data[1].to(device)\n",
    "                                test_outputs = model(data[0].to(device))\n",
    "\n",
    "                                # подсчет ошибки на тесте\n",
    "                                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "                                # подсчет метрики на тесте\n",
    "                                test_running_total += len(data[1])\n",
    "                                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "                                test_running_right += (test_labels == pred_test_labels).sum()\n",
    "\n",
    "                            test_loss_history.append(test_loss.item())\n",
    "                            print(f'Test loss: {test_loss:.3f}.' \n",
    "                                  f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "                            model.train()\n",
    "\n",
    "                        print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487041db",
   "metadata": {},
   "source": [
    "Процесс обучения показал так же весьма близкие результаты: на 5 эпохах точность 96,7%/95,3% соответственно на трейн и тест; на 10 эпохах 98,6%/95%. Для получения более усредненный стабильных результатов обучим итоговоую модель с настройками, взятыми из предыдущих моделей, показавшими на обучении лучшие результаты. Для ускорения процесса я возьму 5 эпох, вместо 10-ти, исхлдя из соображений удешевления процесса (полученные показатели были очень близки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5545104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMFixedLen(vocab_size=max_words, \n",
    "                 embedding_dim=256, hidden_dim=96, \n",
    "                 drop_prob=0.1, use_last=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90c2b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [44/44]. Loss: 0.239. Acc: 0.931. Test loss: 0.630.Test acc: 0.935\n",
      "Epoch [2/5]. Step [44/44]. Loss: 0.145. Acc: 0.946. Test loss: 0.022.Test acc: 0.945\n",
      "Epoch [3/5]. Step [44/44]. Loss: 0.146. Acc: 0.956. Test loss: 0.022.Test acc: 0.951\n",
      "Epoch [4/5]. Step [44/44]. Loss: 0.105. Acc: 0.962. Test loss: 1.380.Test acc: 0.949\n",
      "Epoch [5/5]. Step [44/44]. Loss: 0.068. Acc: 0.969. Test loss: 0.036.Test acc: 0.952\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "th = 0.5\n",
    "epochs = 5\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    running_items, running_right = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # подсчет ошибки на обучении\n",
    "        loss = loss.item()\n",
    "        running_items += len(labels)\n",
    "        # подсчет метрики на обучении\n",
    "        pred_labels = torch.squeeze((outputs > th).int())\n",
    "        running_right += (labels == pred_labels).sum()\n",
    "\n",
    "    # выводим статистику о процессе обучения\n",
    "    model.eval()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "            f'Loss: {loss:.3f}. ' \\\n",
    "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    train_loss_history.append(loss)\n",
    "\n",
    "        # выводим статистику на тестовых данных\n",
    "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
    "    for j, data in enumerate(val_loader):\n",
    "        test_labels = data[1].to(device)\n",
    "        test_outputs = model(data[0].to(device))\n",
    "\n",
    "        # подсчет ошибки на тесте\n",
    "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
    "        # подсчет метрики на тесте\n",
    "        test_running_total += len(data[1])\n",
    "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
    "        test_running_right += (test_labels == pred_test_labels).sum()\n",
    "\n",
    "    test_loss_history.append(test_loss.item())\n",
    "    print(f'Test loss: {test_loss:.3f}.' \n",
    "          f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f378faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79d8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b516b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717e3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01da0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
