{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae58bc19",
   "metadata": {},
   "source": [
    "### 3. Dataset, Dataloader, BatchNorm, Dropout, Оптимизация<Br>\n",
    "    \n",
    "- Создать Dataset для загрузки данных (sklearn.datasets.fetch_california_housing)\n",
    "- Обернуть его в Dataloader\n",
    "- Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)<br>\n",
    "- Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a74f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac79609",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHES = 10\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b5dfc",
   "metadata": {},
   "source": [
    "Создать Dataset для загрузки данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537b8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class real_estate_Dataset(Dataset):\n",
    "    def __init__(self, *init_datasets):\n",
    "        assert all(init_datasets[0].size(0) == init_dataset.size(0) for init_dataset in init_datasets)\n",
    "        self._base_datasets = init_datasets\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self._base_datasets[0].size(0)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return tuple(base_dataset[idx] for base_dataset in self._base_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fc7a8",
   "metadata": {},
   "source": [
    "Обернуть его в Dataloader.\n",
    "\n",
    "Разделить датасет на тест и трейн, разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing = fetch_california_housing()\n",
    "X_train, X_test, y_train, y_test = train_test_split(california_housing.data,\n",
    "                                                    california_housing.target, \n",
    "                                                    test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ef528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация \n",
    "scale = StandardScaler()\n",
    "X_train_s = scale.fit_transform(X_train)\n",
    "X_test_s = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7037e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xt = torch.from_numpy(X_train_s.astype(np.float32)).to(DEVICE)\n",
    "train_yt = torch.from_numpy(y_train.astype(np.float32)).to(DEVICE)\n",
    "\n",
    "test_xt = torch.from_numpy(X_test_s.astype(np.float32)).to(DEVICE)\n",
    "test_yt = torch.from_numpy(y_test.astype(np.float32)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012e673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = real_estate_Dataset(train_xt, train_yt)\n",
    "test_dataset = real_estate_Dataset(test_xt, test_yt)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3f85c",
   "metadata": {},
   "source": [
    "Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "988b970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(NewNet, self).__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=8, out_features=100, bias=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU())\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=100, bias=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU())\n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=60, bias=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.ReLU())\n",
    "        self.block_4 = nn.Sequential(\n",
    "            nn.Linear(in_features=60, out_features=30),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(30),\n",
    "            nn.ReLU())\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(in_features=30, out_features=1, bias=True),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ReLU())\n",
    "  \n",
    "    def forward(self, inp):\n",
    "        out = self.block_1(inp)\n",
    "        out = self.block_2(out)\n",
    "        out = self.block_3(out)\n",
    "        out = self.block_4(out)\n",
    "        out = self.predict(out)\n",
    "        return out[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de04dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_loader, test_loader, net, optimizer):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    best_acc = {'train': None, 'test': None}\n",
    "    net.train()\n",
    "    for epoch in range(EPOCHES):\n",
    "        running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "            outputs = net(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad() #обнулим градиент\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() #выводим статистику о процессе обучения\n",
    "            running_items += len(labels)\n",
    "        \n",
    "            if i % 100 == 0 or (i + 1) == len(train_loader):    #вывод по 100 mini-batches\n",
    "                net.eval()\n",
    "\n",
    "                test_loss, test_running_total, test_loss  = 0.0, 0.0, 0.0\n",
    "                for y, (out_test, lbl_test) in enumerate(test_loader):\n",
    "                    test_outputs = net(out_test)\n",
    "                    test_loss += loss_fn(test_outputs, lbl_test)\n",
    "                    test_running_total += len(lbl_test)\n",
    "            \n",
    "                res_loss_train = running_loss / running_items\n",
    "                res_loss_test = test_loss / test_running_total\n",
    "            \n",
    "                if best_acc['train'] is None or res_loss_train < best_acc['train']:\n",
    "                    best_acc['train'] = res_loss_train\n",
    "            \n",
    "                if best_acc['test'] is None or res_loss_test < best_acc['test']:\n",
    "                    best_acc['test'] = res_loss_train\n",
    "\n",
    "                print(f'Epoch [{epoch + 1}/{EPOCHES}]. ' \\\n",
    "                      f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                      f'Loss: {res_loss_train:.3f}. '\\\n",
    "                      f'Test acc: {res_loss_test:.3f}.')\n",
    "            \n",
    "                running_loss, running_items = 0.0, 0.0\n",
    "                net.train()\n",
    "    print(f\"Best acc train: {best_acc['train']:.3f}. Best acc test: {best_acc['test']:.3f}\")\n",
    " #  print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408be93",
   "metadata": {},
   "source": [
    "Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e188bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acc train</th>\n",
       "      <th>acc test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [optimizer, acc train, acc test]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(columns=['optimizer', 'acc train', 'acc test'])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4b2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор оптимизатора. Adam\n",
    "net = NewNet().to(DEVICE)\n",
    "optimizer = Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98424ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/968]. Loss: 0.210. Test acc: 0.332.\n",
      "Epoch [1/10]. Step [101/968]. Loss: 0.154. Test acc: 0.074.\n",
      "Epoch [1/10]. Step [201/968]. Loss: 0.068. Test acc: 0.052.\n",
      "Epoch [1/10]. Step [301/968]. Loss: 0.055. Test acc: 0.037.\n",
      "Epoch [1/10]. Step [401/968]. Loss: 0.046. Test acc: 0.037.\n",
      "Epoch [1/10]. Step [501/968]. Loss: 0.041. Test acc: 0.033.\n",
      "Epoch [1/10]. Step [601/968]. Loss: 0.046. Test acc: 0.032.\n",
      "Epoch [1/10]. Step [701/968]. Loss: 0.042. Test acc: 0.034.\n",
      "Epoch [1/10]. Step [801/968]. Loss: 0.042. Test acc: 0.057.\n",
      "Epoch [1/10]. Step [901/968]. Loss: 0.039. Test acc: 0.046.\n",
      "Epoch [1/10]. Step [968/968]. Loss: 0.042. Test acc: 0.041.\n",
      "Epoch [2/10]. Step [1/968]. Loss: 0.066. Test acc: 0.040.\n",
      "Epoch [2/10]. Step [101/968]. Loss: 0.040. Test acc: 0.033.\n",
      "Epoch [2/10]. Step [201/968]. Loss: 0.039. Test acc: 0.033.\n",
      "Epoch [2/10]. Step [301/968]. Loss: 0.037. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [401/968]. Loss: 0.032. Test acc: 0.032.\n",
      "Epoch [2/10]. Step [501/968]. Loss: 0.034. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [601/968]. Loss: 0.033. Test acc: 0.040.\n",
      "Epoch [2/10]. Step [701/968]. Loss: 0.029. Test acc: 0.030.\n",
      "Epoch [2/10]. Step [801/968]. Loss: 0.033. Test acc: 0.032.\n",
      "Epoch [2/10]. Step [901/968]. Loss: 0.027. Test acc: 0.032.\n",
      "Epoch [2/10]. Step [968/968]. Loss: 0.033. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [1/968]. Loss: 0.042. Test acc: 0.030.\n",
      "Epoch [3/10]. Step [101/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [201/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [301/968]. Loss: 0.031. Test acc: 0.034.\n",
      "Epoch [3/10]. Step [401/968]. Loss: 0.031. Test acc: 0.036.\n",
      "Epoch [3/10]. Step [501/968]. Loss: 0.029. Test acc: 0.030.\n",
      "Epoch [3/10]. Step [601/968]. Loss: 0.029. Test acc: 0.036.\n",
      "Epoch [3/10]. Step [701/968]. Loss: 0.032. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [801/968]. Loss: 0.033. Test acc: 0.025.\n",
      "Epoch [3/10]. Step [901/968]. Loss: 0.033. Test acc: 0.052.\n",
      "Epoch [3/10]. Step [968/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [1/968]. Loss: 0.040. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [101/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [201/968]. Loss: 0.028. Test acc: 0.067.\n",
      "Epoch [4/10]. Step [301/968]. Loss: 0.033. Test acc: 0.059.\n",
      "Epoch [4/10]. Step [401/968]. Loss: 0.035. Test acc: 0.033.\n",
      "Epoch [4/10]. Step [501/968]. Loss: 0.028. Test acc: 0.060.\n",
      "Epoch [4/10]. Step [601/968]. Loss: 0.030. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [701/968]. Loss: 0.030. Test acc: 0.038.\n",
      "Epoch [4/10]. Step [801/968]. Loss: 0.029. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [901/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [968/968]. Loss: 0.033. Test acc: 0.026.\n",
      "Epoch [5/10]. Step [1/968]. Loss: 0.028. Test acc: 0.026.\n",
      "Epoch [5/10]. Step [101/968]. Loss: 0.030. Test acc: 0.057.\n",
      "Epoch [5/10]. Step [201/968]. Loss: 0.031. Test acc: 0.065.\n",
      "Epoch [5/10]. Step [301/968]. Loss: 0.030. Test acc: 0.032.\n",
      "Epoch [5/10]. Step [401/968]. Loss: 0.033. Test acc: 0.026.\n",
      "Epoch [5/10]. Step [501/968]. Loss: 0.032. Test acc: 0.038.\n",
      "Epoch [5/10]. Step [601/968]. Loss: 0.030. Test acc: 0.031.\n",
      "Epoch [5/10]. Step [701/968]. Loss: 0.032. Test acc: 0.040.\n",
      "Epoch [5/10]. Step [801/968]. Loss: 0.029. Test acc: 0.028.\n",
      "Epoch [5/10]. Step [901/968]. Loss: 0.030. Test acc: 0.029.\n",
      "Epoch [5/10]. Step [968/968]. Loss: 0.034. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [1/968]. Loss: 0.013. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [101/968]. Loss: 0.028. Test acc: 0.024.\n",
      "Epoch [6/10]. Step [201/968]. Loss: 0.028. Test acc: 0.035.\n",
      "Epoch [6/10]. Step [301/968]. Loss: 0.028. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [401/968]. Loss: 0.028. Test acc: 0.056.\n",
      "Epoch [6/10]. Step [501/968]. Loss: 0.027. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [601/968]. Loss: 0.033. Test acc: 0.032.\n",
      "Epoch [6/10]. Step [701/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [801/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [6/10]. Step [901/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [968/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [1/968]. Loss: 0.133. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [101/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [7/10]. Step [201/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [301/968]. Loss: 0.033. Test acc: 0.032.\n",
      "Epoch [7/10]. Step [401/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [501/968]. Loss: 0.027. Test acc: 0.023.\n",
      "Epoch [7/10]. Step [601/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [7/10]. Step [701/968]. Loss: 0.029. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [801/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [901/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [968/968]. Loss: 0.032. Test acc: 0.042.\n",
      "Epoch [8/10]. Step [1/968]. Loss: 0.029. Test acc: 0.043.\n",
      "Epoch [8/10]. Step [101/968]. Loss: 0.029. Test acc: 0.030.\n",
      "Epoch [8/10]. Step [201/968]. Loss: 0.031. Test acc: 0.028.\n",
      "Epoch [8/10]. Step [301/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [8/10]. Step [401/968]. Loss: 0.028. Test acc: 0.033.\n",
      "Epoch [8/10]. Step [501/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [601/968]. Loss: 0.030. Test acc: 0.053.\n",
      "Epoch [8/10]. Step [701/968]. Loss: 0.028. Test acc: 0.047.\n",
      "Epoch [8/10]. Step [801/968]. Loss: 0.028. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [901/968]. Loss: 0.029. Test acc: 0.029.\n",
      "Epoch [8/10]. Step [968/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [1/968]. Loss: 0.013. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [101/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [201/968]. Loss: 0.033. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [301/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [9/10]. Step [401/968]. Loss: 0.028. Test acc: 0.044.\n",
      "Epoch [9/10]. Step [501/968]. Loss: 0.030. Test acc: 0.027.\n",
      "Epoch [9/10]. Step [601/968]. Loss: 0.025. Test acc: 0.026.\n",
      "Epoch [9/10]. Step [701/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [9/10]. Step [801/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [9/10]. Step [901/968]. Loss: 0.030. Test acc: 0.054.\n",
      "Epoch [9/10]. Step [968/968]. Loss: 0.033. Test acc: 0.052.\n",
      "Epoch [10/10]. Step [1/968]. Loss: 0.009. Test acc: 0.052.\n",
      "Epoch [10/10]. Step [101/968]. Loss: 0.026. Test acc: 0.058.\n",
      "Epoch [10/10]. Step [201/968]. Loss: 0.031. Test acc: 0.028.\n",
      "Epoch [10/10]. Step [301/968]. Loss: 0.030. Test acc: 0.031.\n",
      "Epoch [10/10]. Step [401/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [10/10]. Step [501/968]. Loss: 0.029. Test acc: 0.042.\n",
      "Epoch [10/10]. Step [601/968]. Loss: 0.028. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [701/968]. Loss: 0.029. Test acc: 0.042.\n",
      "Epoch [10/10]. Step [801/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [901/968]. Loss: 0.029. Test acc: 0.035.\n",
      "Epoch [10/10]. Step [968/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Best acc train: 0.009. Best acc test: 0.013\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "train_loop(train_loader, test_loader, net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505cc199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Инна\\AppData\\Local\\Temp\\ipykernel_14372\\1447431330.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acc train</th>\n",
       "      <th>acc test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer acc train acc test\n",
       "0      Adam     0.009    0.013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = {'train': 0.009, 'test': 0.013}\n",
    "name='Adam'\n",
    "metrics_df = metrics_df.append({\n",
    "    'optimizer': name,\n",
    "    'acc train': best_acc['train'],\n",
    "    'acc test': best_acc['test'],\n",
    "}, ignore_index=True)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb891f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NewNet().to(DEVICE)\n",
    "optimizer = RMSprop(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e44473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/968]. Loss: 0.242. Test acc: 0.354.\n",
      "Epoch [1/10]. Step [101/968]. Loss: 0.085. Test acc: 0.041.\n",
      "Epoch [1/10]. Step [201/968]. Loss: 0.048. Test acc: 0.043.\n",
      "Epoch [1/10]. Step [301/968]. Loss: 0.048. Test acc: 0.035.\n",
      "Epoch [1/10]. Step [401/968]. Loss: 0.047. Test acc: 0.062.\n",
      "Epoch [1/10]. Step [501/968]. Loss: 0.041. Test acc: 0.037.\n",
      "Epoch [1/10]. Step [601/968]. Loss: 0.040. Test acc: 0.033.\n",
      "Epoch [1/10]. Step [701/968]. Loss: 0.042. Test acc: 0.030.\n",
      "Epoch [1/10]. Step [801/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [1/10]. Step [901/968]. Loss: 0.033. Test acc: 0.030.\n",
      "Epoch [1/10]. Step [968/968]. Loss: 0.034. Test acc: 0.030.\n",
      "Epoch [2/10]. Step [1/968]. Loss: 0.036. Test acc: 0.031.\n",
      "Epoch [2/10]. Step [101/968]. Loss: 0.031. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [201/968]. Loss: 0.032. Test acc: 0.036.\n",
      "Epoch [2/10]. Step [301/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [401/968]. Loss: 0.033. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [501/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [601/968]. Loss: 0.034. Test acc: 0.037.\n",
      "Epoch [2/10]. Step [701/968]. Loss: 0.031. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [801/968]. Loss: 0.034. Test acc: 0.056.\n",
      "Epoch [2/10]. Step [901/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [968/968]. Loss: 0.031. Test acc: 0.047.\n",
      "Epoch [3/10]. Step [1/968]. Loss: 0.016. Test acc: 0.046.\n",
      "Epoch [3/10]. Step [101/968]. Loss: 0.032. Test acc: 0.047.\n",
      "Epoch [3/10]. Step [201/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [3/10]. Step [301/968]. Loss: 0.030. Test acc: 0.060.\n",
      "Epoch [3/10]. Step [401/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [501/968]. Loss: 0.034. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [601/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [701/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [801/968]. Loss: 0.030. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [901/968]. Loss: 0.035. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [968/968]. Loss: 0.032. Test acc: 0.032.\n",
      "Epoch [4/10]. Step [1/968]. Loss: 0.037. Test acc: 0.041.\n",
      "Epoch [4/10]. Step [101/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [4/10]. Step [201/968]. Loss: 0.030. Test acc: 0.031.\n",
      "Epoch [4/10]. Step [301/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [4/10]. Step [401/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [501/968]. Loss: 0.030. Test acc: 0.038.\n",
      "Epoch [4/10]. Step [601/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [701/968]. Loss: 0.028. Test acc: 0.044.\n",
      "Epoch [4/10]. Step [801/968]. Loss: 0.029. Test acc: 0.054.\n",
      "Epoch [4/10]. Step [901/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [4/10]. Step [968/968]. Loss: 0.031. Test acc: 0.041.\n",
      "Epoch [5/10]. Step [1/968]. Loss: 0.009. Test acc: 0.040.\n",
      "Epoch [5/10]. Step [101/968]. Loss: 0.030. Test acc: 0.033.\n",
      "Epoch [5/10]. Step [201/968]. Loss: 0.027. Test acc: 0.037.\n",
      "Epoch [5/10]. Step [301/968]. Loss: 0.029. Test acc: 0.042.\n",
      "Epoch [5/10]. Step [401/968]. Loss: 0.034. Test acc: 0.049.\n",
      "Epoch [5/10]. Step [501/968]. Loss: 0.028. Test acc: 0.039.\n",
      "Epoch [5/10]. Step [601/968]. Loss: 0.031. Test acc: 0.049.\n",
      "Epoch [5/10]. Step [701/968]. Loss: 0.028. Test acc: 0.023.\n",
      "Epoch [5/10]. Step [801/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [901/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [968/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [6/10]. Step [1/968]. Loss: 0.027. Test acc: 0.026.\n",
      "Epoch [6/10]. Step [101/968]. Loss: 0.029. Test acc: 0.051.\n",
      "Epoch [6/10]. Step [201/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [6/10]. Step [301/968]. Loss: 0.027. Test acc: 0.026.\n",
      "Epoch [6/10]. Step [401/968]. Loss: 0.033. Test acc: 0.043.\n",
      "Epoch [6/10]. Step [501/968]. Loss: 0.032. Test acc: 0.031.\n",
      "Epoch [6/10]. Step [601/968]. Loss: 0.031. Test acc: 0.031.\n",
      "Epoch [6/10]. Step [701/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [6/10]. Step [801/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [901/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [6/10]. Step [968/968]. Loss: 0.029. Test acc: 0.032.\n",
      "Epoch [7/10]. Step [1/968]. Loss: 0.020. Test acc: 0.031.\n",
      "Epoch [7/10]. Step [101/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [7/10]. Step [201/968]. Loss: 0.029. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [301/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [401/968]. Loss: 0.027. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [501/968]. Loss: 0.030. Test acc: 0.061.\n",
      "Epoch [7/10]. Step [601/968]. Loss: 0.029. Test acc: 0.033.\n",
      "Epoch [7/10]. Step [701/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [801/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [901/968]. Loss: 0.027. Test acc: 0.031.\n",
      "Epoch [7/10]. Step [968/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [8/10]. Step [1/968]. Loss: 0.021. Test acc: 0.025.\n",
      "Epoch [8/10]. Step [101/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [8/10]. Step [201/968]. Loss: 0.028. Test acc: 0.029.\n",
      "Epoch [8/10]. Step [301/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [8/10]. Step [401/968]. Loss: 0.028. Test acc: 0.028.\n",
      "Epoch [8/10]. Step [501/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [601/968]. Loss: 0.032. Test acc: 0.024.\n",
      "Epoch [8/10]. Step [701/968]. Loss: 0.030. Test acc: 0.047.\n",
      "Epoch [8/10]. Step [801/968]. Loss: 0.029. Test acc: 0.045.\n",
      "Epoch [8/10]. Step [901/968]. Loss: 0.030. Test acc: 0.029.\n",
      "Epoch [8/10]. Step [968/968]. Loss: 0.028. Test acc: 0.023.\n",
      "Epoch [9/10]. Step [1/968]. Loss: 0.028. Test acc: 0.023.\n",
      "Epoch [9/10]. Step [101/968]. Loss: 0.032. Test acc: 0.022.\n",
      "Epoch [9/10]. Step [201/968]. Loss: 0.028. Test acc: 0.044.\n",
      "Epoch [9/10]. Step [301/968]. Loss: 0.029. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [401/968]. Loss: 0.028. Test acc: 0.032.\n",
      "Epoch [9/10]. Step [501/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [601/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [701/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [9/10]. Step [801/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [9/10]. Step [901/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [968/968]. Loss: 0.025. Test acc: 0.023.\n",
      "Epoch [10/10]. Step [1/968]. Loss: 0.049. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [101/968]. Loss: 0.034. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [201/968]. Loss: 0.028. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [301/968]. Loss: 0.030. Test acc: 0.028.\n",
      "Epoch [10/10]. Step [401/968]. Loss: 0.025. Test acc: 0.046.\n",
      "Epoch [10/10]. Step [501/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [10/10]. Step [601/968]. Loss: 0.028. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [701/968]. Loss: 0.029. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [801/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [10/10]. Step [901/968]. Loss: 0.026. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [968/968]. Loss: 0.028. Test acc: 0.042.\n",
      "Best acc train: 0.009. Best acc test: 0.021\n",
      "CPU times: total: 2min 52s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loop(train_loader, test_loader, net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89343901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Инна\\AppData\\Local\\Temp\\ipykernel_14372\\3048120252.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acc train</th>\n",
       "      <th>acc test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer acc train acc test\n",
       "0      Adam     0.009    0.013\n",
       "1   RMSprop     0.009    0.021"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = {'train': 0.009, 'test': 0.021}\n",
    "name='RMSprop'\n",
    "metrics_df = metrics_df.append({\n",
    "    'optimizer': name,\n",
    "    'acc train': best_acc['train'],\n",
    "    'acc test': best_acc['test'],\n",
    "}, ignore_index=True)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5da1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NewNet().to(DEVICE)\n",
    "optimizer = SGD(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "684860ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/968]. Loss: 0.289. Test acc: 0.354.\n",
      "Epoch [1/10]. Step [101/968]. Loss: 0.141. Test acc: 0.060.\n",
      "Epoch [1/10]. Step [201/968]. Loss: 0.065. Test acc: 0.044.\n",
      "Epoch [1/10]. Step [301/968]. Loss: 0.053. Test acc: 0.041.\n",
      "Epoch [1/10]. Step [401/968]. Loss: 0.053. Test acc: 0.039.\n",
      "Epoch [1/10]. Step [501/968]. Loss: 0.039. Test acc: 0.035.\n",
      "Epoch [1/10]. Step [601/968]. Loss: 0.040. Test acc: 0.044.\n",
      "Epoch [1/10]. Step [701/968]. Loss: 0.034. Test acc: 0.033.\n",
      "Epoch [1/10]. Step [801/968]. Loss: 0.038. Test acc: 0.031.\n",
      "Epoch [1/10]. Step [901/968]. Loss: 0.038. Test acc: 0.032.\n",
      "Epoch [1/10]. Step [968/968]. Loss: 0.034. Test acc: 0.030.\n",
      "Epoch [2/10]. Step [1/968]. Loss: 0.036. Test acc: 0.030.\n",
      "Epoch [2/10]. Step [101/968]. Loss: 0.036. Test acc: 0.034.\n",
      "Epoch [2/10]. Step [201/968]. Loss: 0.036. Test acc: 0.032.\n",
      "Epoch [2/10]. Step [301/968]. Loss: 0.036. Test acc: 0.031.\n",
      "Epoch [2/10]. Step [401/968]. Loss: 0.035. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [501/968]. Loss: 0.035. Test acc: 0.032.\n",
      "Epoch [2/10]. Step [601/968]. Loss: 0.034. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [701/968]. Loss: 0.033. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [801/968]. Loss: 0.036. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [901/968]. Loss: 0.035. Test acc: 0.031.\n",
      "Epoch [2/10]. Step [968/968]. Loss: 0.035. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [1/968]. Loss: 0.021. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [101/968]. Loss: 0.034. Test acc: 0.040.\n",
      "Epoch [3/10]. Step [201/968]. Loss: 0.035. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [301/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [401/968]. Loss: 0.031. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [501/968]. Loss: 0.030. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [601/968]. Loss: 0.033. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [701/968]. Loss: 0.032. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [801/968]. Loss: 0.034. Test acc: 0.029.\n",
      "Epoch [3/10]. Step [901/968]. Loss: 0.036. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [968/968]. Loss: 0.035. Test acc: 0.031.\n",
      "Epoch [4/10]. Step [1/968]. Loss: 0.063. Test acc: 0.031.\n",
      "Epoch [4/10]. Step [101/968]. Loss: 0.030. Test acc: 0.029.\n",
      "Epoch [4/10]. Step [201/968]. Loss: 0.033. Test acc: 0.045.\n",
      "Epoch [4/10]. Step [301/968]. Loss: 0.034. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [401/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [501/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [601/968]. Loss: 0.035. Test acc: 0.033.\n",
      "Epoch [4/10]. Step [701/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [4/10]. Step [801/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [901/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [968/968]. Loss: 0.033. Test acc: 0.031.\n",
      "Epoch [5/10]. Step [1/968]. Loss: 0.016. Test acc: 0.031.\n",
      "Epoch [5/10]. Step [101/968]. Loss: 0.032. Test acc: 0.032.\n",
      "Epoch [5/10]. Step [201/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [301/968]. Loss: 0.031. Test acc: 0.028.\n",
      "Epoch [5/10]. Step [401/968]. Loss: 0.032. Test acc: 0.031.\n",
      "Epoch [5/10]. Step [501/968]. Loss: 0.034. Test acc: 0.033.\n",
      "Epoch [5/10]. Step [601/968]. Loss: 0.034. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [701/968]. Loss: 0.031. Test acc: 0.034.\n",
      "Epoch [5/10]. Step [801/968]. Loss: 0.033. Test acc: 0.061.\n",
      "Epoch [5/10]. Step [901/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [968/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [1/968]. Loss: 0.039. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [101/968]. Loss: 0.032. Test acc: 0.029.\n",
      "Epoch [6/10]. Step [201/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [301/968]. Loss: 0.032. Test acc: 0.029.\n",
      "Epoch [6/10]. Step [401/968]. Loss: 0.030. Test acc: 0.030.\n",
      "Epoch [6/10]. Step [501/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [601/968]. Loss: 0.034. Test acc: 0.034.\n",
      "Epoch [6/10]. Step [701/968]. Loss: 0.032. Test acc: 0.042.\n",
      "Epoch [6/10]. Step [801/968]. Loss: 0.029. Test acc: 0.033.\n",
      "Epoch [6/10]. Step [901/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [968/968]. Loss: 0.033. Test acc: 0.028.\n",
      "Epoch [7/10]. Step [1/968]. Loss: 0.024. Test acc: 0.029.\n",
      "Epoch [7/10]. Step [101/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [201/968]. Loss: 0.030. Test acc: 0.035.\n",
      "Epoch [7/10]. Step [301/968]. Loss: 0.032. Test acc: 0.031.\n",
      "Epoch [7/10]. Step [401/968]. Loss: 0.030. Test acc: 0.028.\n",
      "Epoch [7/10]. Step [501/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [601/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [701/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [801/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [901/968]. Loss: 0.034. Test acc: 0.033.\n",
      "Epoch [7/10]. Step [968/968]. Loss: 0.034. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [1/968]. Loss: 0.025. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [101/968]. Loss: 0.027. Test acc: 0.033.\n",
      "Epoch [8/10]. Step [201/968]. Loss: 0.031. Test acc: 0.033.\n",
      "Epoch [8/10]. Step [301/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [401/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [8/10]. Step [501/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [8/10]. Step [601/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [8/10]. Step [701/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [8/10]. Step [801/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [901/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [8/10]. Step [968/968]. Loss: 0.034. Test acc: 0.036.\n",
      "Epoch [9/10]. Step [1/968]. Loss: 0.017. Test acc: 0.036.\n",
      "Epoch [9/10]. Step [101/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [201/968]. Loss: 0.032. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [301/968]. Loss: 0.029. Test acc: 0.034.\n",
      "Epoch [9/10]. Step [401/968]. Loss: 0.034. Test acc: 0.033.\n",
      "Epoch [9/10]. Step [501/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [601/968]. Loss: 0.027. Test acc: 0.030.\n",
      "Epoch [9/10]. Step [701/968]. Loss: 0.031. Test acc: 0.031.\n",
      "Epoch [9/10]. Step [801/968]. Loss: 0.032. Test acc: 0.029.\n",
      "Epoch [9/10]. Step [901/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [9/10]. Step [968/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [1/968]. Loss: 0.036. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [101/968]. Loss: 0.029. Test acc: 0.029.\n",
      "Epoch [10/10]. Step [201/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [301/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [401/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [501/968]. Loss: 0.033. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [601/968]. Loss: 0.032. Test acc: 0.031.\n",
      "Epoch [10/10]. Step [701/968]. Loss: 0.035. Test acc: 0.033.\n",
      "Epoch [10/10]. Step [801/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [10/10]. Step [901/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [968/968]. Loss: 0.035. Test acc: 0.060.\n",
      "Best acc train: 0.016. Best acc test: 0.021\n",
      "CPU times: total: 2min 32s\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_loop(train_loader, test_loader, net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050c99ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Инна\\AppData\\Local\\Temp\\ipykernel_14372\\1002281236.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acc train</th>\n",
       "      <th>acc test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer acc train acc test\n",
       "0      Adam     0.009    0.013\n",
       "1   RMSprop     0.009    0.021\n",
       "2       SGD     0.016    0.021"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = {'train': 0.016, 'test': 0.021}\n",
    "name='SGD'\n",
    "metrics_df = metrics_df.append({\n",
    "    'optimizer': name,\n",
    "    'acc train': best_acc['train'],\n",
    "    'acc test': best_acc['test'],\n",
    "}, ignore_index=True)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7c23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NewNet().to(DEVICE)\n",
    "optimizer = SGD(net.parameters(), lr=LR, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "914cf5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/968]. Loss: 0.247. Test acc: 0.354.\n",
      "Epoch [1/10]. Step [101/968]. Loss: 0.096. Test acc: 0.049.\n",
      "Epoch [1/10]. Step [201/968]. Loss: 0.052. Test acc: 0.040.\n",
      "Epoch [1/10]. Step [301/968]. Loss: 0.040. Test acc: 0.037.\n",
      "Epoch [1/10]. Step [401/968]. Loss: 0.042. Test acc: 0.033.\n",
      "Epoch [1/10]. Step [501/968]. Loss: 0.036. Test acc: 0.031.\n",
      "Epoch [1/10]. Step [601/968]. Loss: 0.038. Test acc: 0.032.\n",
      "Epoch [1/10]. Step [701/968]. Loss: 0.037. Test acc: 0.031.\n",
      "Epoch [1/10]. Step [801/968]. Loss: 0.036. Test acc: 0.038.\n",
      "Epoch [1/10]. Step [901/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [1/10]. Step [968/968]. Loss: 0.033. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [1/968]. Loss: 0.021. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [101/968]. Loss: 0.035. Test acc: 0.042.\n",
      "Epoch [2/10]. Step [201/968]. Loss: 0.034. Test acc: 0.036.\n",
      "Epoch [2/10]. Step [301/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [401/968]. Loss: 0.032. Test acc: 0.029.\n",
      "Epoch [2/10]. Step [501/968]. Loss: 0.036. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [601/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [701/968]. Loss: 0.034. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [801/968]. Loss: 0.034. Test acc: 0.027.\n",
      "Epoch [2/10]. Step [901/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [2/10]. Step [968/968]. Loss: 0.035. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [1/968]. Loss: 0.023. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [101/968]. Loss: 0.035. Test acc: 0.031.\n",
      "Epoch [3/10]. Step [201/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [301/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [401/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [501/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [3/10]. Step [601/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [3/10]. Step [701/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [801/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [901/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [3/10]. Step [968/968]. Loss: 0.030. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [1/968]. Loss: 0.020. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [101/968]. Loss: 0.036. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [201/968]. Loss: 0.032. Test acc: 0.028.\n",
      "Epoch [4/10]. Step [301/968]. Loss: 0.030. Test acc: 0.036.\n",
      "Epoch [4/10]. Step [401/968]. Loss: 0.032. Test acc: 0.035.\n",
      "Epoch [4/10]. Step [501/968]. Loss: 0.035. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [601/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [701/968]. Loss: 0.031. Test acc: 0.038.\n",
      "Epoch [4/10]. Step [801/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [4/10]. Step [901/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [4/10]. Step [968/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [1/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [101/968]. Loss: 0.029. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [201/968]. Loss: 0.031. Test acc: 0.033.\n",
      "Epoch [5/10]. Step [301/968]. Loss: 0.033. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [401/968]. Loss: 0.033. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [501/968]. Loss: 0.028. Test acc: 0.027.\n",
      "Epoch [5/10]. Step [601/968]. Loss: 0.031. Test acc: 0.026.\n",
      "Epoch [5/10]. Step [701/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [801/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [901/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [5/10]. Step [968/968]. Loss: 0.029. Test acc: 0.032.\n",
      "Epoch [6/10]. Step [1/968]. Loss: 0.023. Test acc: 0.033.\n",
      "Epoch [6/10]. Step [101/968]. Loss: 0.032. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [201/968]. Loss: 0.030. Test acc: 0.042.\n",
      "Epoch [6/10]. Step [301/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [401/968]. Loss: 0.031. Test acc: 0.039.\n",
      "Epoch [6/10]. Step [501/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [601/968]. Loss: 0.031. Test acc: 0.027.\n",
      "Epoch [6/10]. Step [701/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [801/968]. Loss: 0.028. Test acc: 0.025.\n",
      "Epoch [6/10]. Step [901/968]. Loss: 0.028. Test acc: 0.028.\n",
      "Epoch [6/10]. Step [968/968]. Loss: 0.034. Test acc: 0.027.\n",
      "Epoch [7/10]. Step [1/968]. Loss: 0.018. Test acc: 0.027.\n",
      "Epoch [7/10]. Step [101/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [201/968]. Loss: 0.033. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [301/968]. Loss: 0.030. Test acc: 0.029.\n",
      "Epoch [7/10]. Step [401/968]. Loss: 0.032. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [501/968]. Loss: 0.033. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [601/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [701/968]. Loss: 0.028. Test acc: 0.026.\n",
      "Epoch [7/10]. Step [801/968]. Loss: 0.028. Test acc: 0.025.\n",
      "Epoch [7/10]. Step [901/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [7/10]. Step [968/968]. Loss: 0.030. Test acc: 0.036.\n",
      "Epoch [8/10]. Step [1/968]. Loss: 0.029. Test acc: 0.035.\n",
      "Epoch [8/10]. Step [101/968]. Loss: 0.028. Test acc: 0.025.\n",
      "Epoch [8/10]. Step [201/968]. Loss: 0.031. Test acc: 0.036.\n",
      "Epoch [8/10]. Step [301/968]. Loss: 0.028. Test acc: 0.041.\n",
      "Epoch [8/10]. Step [401/968]. Loss: 0.032. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [501/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [601/968]. Loss: 0.033. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [701/968]. Loss: 0.029. Test acc: 0.026.\n",
      "Epoch [8/10]. Step [801/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [8/10]. Step [901/968]. Loss: 0.028. Test acc: 0.027.\n",
      "Epoch [8/10]. Step [968/968]. Loss: 0.030. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [1/968]. Loss: 0.034. Test acc: 0.026.\n",
      "Epoch [9/10]. Step [101/968]. Loss: 0.030. Test acc: 0.026.\n",
      "Epoch [9/10]. Step [201/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [301/968]. Loss: 0.032. Test acc: 0.023.\n",
      "Epoch [9/10]. Step [401/968]. Loss: 0.033. Test acc: 0.043.\n",
      "Epoch [9/10]. Step [501/968]. Loss: 0.030. Test acc: 0.025.\n",
      "Epoch [9/10]. Step [601/968]. Loss: 0.031. Test acc: 0.047.\n",
      "Epoch [9/10]. Step [701/968]. Loss: 0.029. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [801/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [901/968]. Loss: 0.028. Test acc: 0.024.\n",
      "Epoch [9/10]. Step [968/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [10/10]. Step [1/968]. Loss: 0.019. Test acc: 0.027.\n",
      "Epoch [10/10]. Step [101/968]. Loss: 0.029. Test acc: 0.030.\n",
      "Epoch [10/10]. Step [201/968]. Loss: 0.031. Test acc: 0.025.\n",
      "Epoch [10/10]. Step [301/968]. Loss: 0.032. Test acc: 0.030.\n",
      "Epoch [10/10]. Step [401/968]. Loss: 0.031. Test acc: 0.040.\n",
      "Epoch [10/10]. Step [501/968]. Loss: 0.029. Test acc: 0.023.\n",
      "Epoch [10/10]. Step [601/968]. Loss: 0.028. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [701/968]. Loss: 0.030. Test acc: 0.038.\n",
      "Epoch [10/10]. Step [801/968]. Loss: 0.031. Test acc: 0.024.\n",
      "Epoch [10/10]. Step [901/968]. Loss: 0.029. Test acc: 0.027.\n",
      "Epoch [10/10]. Step [968/968]. Loss: 0.027. Test acc: 0.025.\n",
      "Best acc train: 0.018. Best acc test: 0.021\n",
      "CPU times: total: 2min 36s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loop(train_loader, test_loader, net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1d08be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Инна\\AppData\\Local\\Temp\\ipykernel_14372\\935377102.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>acc train</th>\n",
       "      <th>acc test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD + Momentum (0,5)</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              optimizer acc train acc test\n",
       "0                  Adam     0.009    0.013\n",
       "1               RMSprop     0.009    0.021\n",
       "2                   SGD     0.016    0.021\n",
       "3  SGD + Momentum (0,5)     0.018    0.021"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = {'train': 0.018, 'test': 0.021}\n",
    "name='SGD + Momentum (0,5)'\n",
    "metrics_df = metrics_df.append({\n",
    "    'optimizer': name,\n",
    "    'acc train': best_acc['train'],\n",
    "    'acc test': best_acc['test'],\n",
    "}, ignore_index=True)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771e3ea",
   "metadata": {},
   "source": [
    "Если подобрать последний критерий, то можно значительно улучшить точность с оптимизатором SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc22084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
